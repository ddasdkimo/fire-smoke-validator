#!/usr/bin/env python3
"""
ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±
ä¸Šå‚³å½±ç‰‡å¾Œä½¿ç”¨ best.pt æ¨¡å‹æƒæï¼ŒæŒ‰ ReID åˆ†çµ„äº‹ä»¶ï¼Œå¿«é€Ÿæ¨™è¨»æœ‰/ç„¡èª¤åˆ¤
"""

import gradio as gr
import cv2
import numpy as np
from pathlib import Path
import json
import uuid
from datetime import datetime
import tempfile
import os
from collections import defaultdict
import zipfile

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("âš ï¸  Ultralytics æœªå®‰è£ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬åµæ¸¬")

try:
    import supervision as sv
    SUPERVISION_AVAILABLE = True
except ImportError:
    SUPERVISION_AVAILABLE = False
    print("âš ï¸  Supervision æœªå®‰è£ï¼ŒReID åŠŸèƒ½å—é™")

class VideoAnalyzer:
    def __init__(self):
        self.model_path = "best.pt"
        self.work_dir = Path("temp_analysis")
        self.work_dir.mkdir(exist_ok=True)
        self.dataset_dir = Path("dataset")
        self.dataset_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ¨¡å‹
        if ULTRALYTICS_AVAILABLE and Path(self.model_path).exists():
            import torch
            # æª¢æŸ¥ä¸¦ä½¿ç”¨ MPS
            if torch.backends.mps.is_available():
                device = 'mps'
                print("âœ… ä½¿ç”¨ Mac MPS åŠ é€Ÿ")
            else:
                device = 'cpu'
                print("â„¹ï¸  ä½¿ç”¨ CPU æ¨¡å¼")
            
            self.model = YOLO(self.model_path)
            self.model.to(device)
            print(f"âœ… å·²è¼‰å…¥ best.pt æ¨¡å‹åˆ° {device}")
        else:
            self.model = None
            print("âš ï¸  æœªæ‰¾åˆ° best.ptï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬åµæ¸¬")
        
        # åˆå§‹åŒ–è¿½è¹¤å™¨
        if SUPERVISION_AVAILABLE:
            self.tracker = sv.ByteTrack()
        else:
            self.tracker = None
        
        self.current_events = []
        self.session_id = None
    
    def analyze_videos(self, video_paths):
        """åˆ†æå¤šå€‹å½±ç‰‡ï¼Œæå–äº‹ä»¶"""
        try:
            if not video_paths:
                return "è«‹ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ", [], ""
            
            # ç¢ºä¿æ˜¯ä¸²åˆ—
            if not isinstance(video_paths, list):
                video_paths = [video_paths]
            
            self.session_id = str(uuid.uuid4())[:8]
            session_dir = self.work_dir / self.session_id
            session_dir.mkdir(exist_ok=True)
            
            all_video_detections = []
            video_summaries = []
            
            print(f"æº–å‚™åˆ†æ {len(video_paths)} å€‹å½±ç‰‡...")
            
            # è™•ç†æ¯å€‹å½±ç‰‡
            for video_idx, video_path in enumerate(video_paths):
                video_name = Path(video_path).name
                print(f"\nåˆ†æå½±ç‰‡ {video_idx+1}/{len(video_paths)}: {video_name}")
                
                # åˆ†æå–®å€‹å½±ç‰‡
                video_detections, summary = self._analyze_single_video(video_path, video_idx, video_name)
                video_summaries.append(summary)
                all_video_detections.extend(video_detections)
            
            print(f"\nç¸½å…±åµæ¸¬åˆ° {len(all_video_detections)} å€‹ç‰©ä»¶ï¼Œé–‹å§‹åˆ†çµ„...")
            
            # æŒ‰ ReID åˆ†çµ„äº‹ä»¶
            events = self._group_detections_by_reid(all_video_detections, session_dir)
            
            print(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶")
            
            self.current_events = events
            
            # ç”Ÿæˆåˆ†æçµæœ
            result_text = f"""
åˆ†æå®Œæˆï¼
å½±ç‰‡æ•¸é‡ï¼š{len(video_paths)} å€‹
"""
            for summary in video_summaries:
                result_text += f"\n{summary['name']}: {summary['detections']} å€‹åµæ¸¬, {summary['duration']:.1f} ç§’"
            
            result_text += f"""

ç¸½åµæ¸¬æ•¸ï¼š{len(all_video_detections)} å€‹
åˆ†çµ„äº‹ä»¶æ•¸ï¼š{len(events)} å€‹

ä½¿ç”¨ä¸Šæ–¹è¼ªæ’­ä»‹é¢é€²è¡Œæ¨™è¨»
            """.strip()
            
            # ç”Ÿæˆäº‹ä»¶ç¸®åœ–ä¾›é¸æ“‡
            event_gallery = []
            for i, event in enumerate(events):
                if event['frames']:
                    # ä½¿ç”¨ç¬¬ä¸€å¹€ä½œç‚ºä»£è¡¨åœ–åƒ
                    first_frame_path = event['frames'][0]['image_path']
                    event_gallery.append(first_frame_path)
            
            return result_text, event_gallery, f"æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶"
            
        except Exception as e:
            print(f"åˆ†æå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"åˆ†æå¤±æ•—: {str(e)}", [], "éŒ¯èª¤"
    
    def _analyze_single_video(self, video_path, video_idx, video_name):
        """åˆ†æå–®å€‹å½±ç‰‡"""
        # æ‰“é–‹å½±ç‰‡
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"ç„¡æ³•æ‰“é–‹å½±ç‰‡æª”æ¡ˆ: {video_name}")
            return [], {'name': video_name, 'detections': 0, 'duration': 0}
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        print(f"å½±ç‰‡è³‡è¨Š: {total_frames} å¹€, {fps:.1f} FPS, {duration:.1f} ç§’")
        
        # æ”¶é›†åµæ¸¬çµæœ
        video_detections = []
        frame_idx = 0
        sample_interval = max(1, int(fps * 1.0))  # æ¯ 1 ç§’æ¡æ¨£ä¸€å¹€
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_idx % 100 == 0:  # æ¯ 100 å¹€é¡¯ç¤ºé€²åº¦
                print(f"åˆ†æé€²åº¦: {frame_idx}/{total_frames} å¹€ ({frame_idx/total_frames*100:.1f}%)")
            
            # æ¡æ¨£ç­–ç•¥ï¼šæ¯ç§’å–ä¸€å¹€
            if frame_idx % sample_interval == 0:
                timestamp = frame_idx / fps
                detections = self._detect_objects(frame, frame_idx, timestamp)
                if detections:
                    # åŠ ä¸Šå½±ç‰‡ä¾†æºè³‡è¨Š
                    for det in detections:
                        det['video_name'] = video_name
                        det['video_idx'] = video_idx
                    video_detections.extend(detections)
            
            frame_idx += 1
            
            # é‡‹æ”¾è¨˜æ†¶é«”
            if frame_idx % 500 == 0:
                import gc
                gc.collect()
        
        cap.release()
        
        summary = {
            'name': video_name,
            'detections': len(video_detections),
            'duration': duration
        }
        
        return video_detections, summary
    
    def _detect_objects(self, frame, frame_idx, timestamp):
        """åœ¨å¹€ä¸­åµæ¸¬ç‰©ä»¶"""
        try:
            if self.model:
                # ä½¿ç”¨çœŸå¯¦çš„ YOLO æ¨¡å‹ï¼ˆæœƒè‡ªå‹•ä½¿ç”¨å·²è¨­å®šçš„ deviceï¼‰
                results = self.model(frame, conf=0.3, verbose=False)
                detections = []
            
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        cls = int(box.cls[0].cpu().numpy())
                        
                        # è£åˆ‡æª¢æ¸¬å€åŸŸ
                        crop = frame[int(y1):int(y2), int(x1):int(x2)]
                        if crop.size > 0:
                            detections.append({
                                'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                'confidence': float(conf),
                                'class': int(cls),
                                'frame_idx': frame_idx,
                                'timestamp': timestamp,
                                'crop': crop,
                                'full_frame': frame.copy()  # ä¿å­˜å®Œæ•´ç•«é¢
                            })
                return detections
            else:
                # æ¨¡æ“¬åµæ¸¬ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
                h, w = frame.shape[:2]
                if frame_idx % 10 == 0:  # æ¯10å¹€æ¨¡æ“¬ä¸€å€‹åµæ¸¬
                    x1, y1 = w//4, h//4
                    x2, y2 = w*3//4, h*3//4
                    crop = frame[y1:y2, x1:x2]
                    return [{
                        'bbox': [x1, y1, x2, y2],
                        'confidence': 0.8,
                        'class': 0,
                        'frame_idx': frame_idx,
                        'timestamp': timestamp,
                        'crop': crop,
                        'full_frame': frame.copy()
                    }]
                return []
        except Exception as e:
            print(f"åµæ¸¬ç‰©ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def _group_detections_by_reid(self, detections, session_dir):
        """ä½¿ç”¨ ReID åˆ†çµ„åµæ¸¬çµæœ"""
        try:
            if not detections:
                return []
            
            # ç°¡åŒ–ç‰ˆåˆ†çµ„ï¼šæŒ‰ä½ç½®å’Œæ™‚é–“æ¥è¿‘åº¦åˆ†çµ„
            events = []
            grouped = defaultdict(list)
            
            for det in detections:
                # è¨ˆç®—ä¸­å¿ƒé»
                x1, y1, x2, y2 = det['bbox']
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                # æ‰¾åˆ°æœ€è¿‘çš„çµ„åˆ¥
                best_group = None
                min_distance = float('inf')
                
                for group_id, group_dets in grouped.items():
                    # è¨ˆç®—èˆ‡çµ„åˆ¥ä¸­æœ€å¾Œä¸€å€‹åµæ¸¬çš„è·é›¢
                    last_det = group_dets[-1]
                    last_x1, last_y1, last_x2, last_y2 = last_det['bbox']
                    last_center_x = (last_x1 + last_x2) / 2
                    last_center_y = (last_y1 + last_y2) / 2
                    
                    distance = np.sqrt((center_x - last_center_x)**2 + (center_y - last_center_y)**2)
                    time_diff = abs(det['timestamp'] - last_det['timestamp'])
                    
                    # å¦‚æœä½ç½®æ¥è¿‘ä¸”æ™‚é–“å·®ä¸å¤§ï¼Œè¦–ç‚ºåŒä¸€äº‹ä»¶
                    if distance < 100 and time_diff < 10:  # å¯èª¿æ•´çš„é–¾å€¼
                        if distance < min_distance:
                            min_distance = distance
                            best_group = group_id
                
                if best_group is not None:
                    grouped[best_group].append(det)
                else:
                    # å‰µå»ºæ–°çµ„åˆ¥
                    new_group_id = len(grouped)
                    grouped[new_group_id].append(det)
            
            # è½‰æ›ç‚ºäº‹ä»¶æ ¼å¼
            for group_id, group_dets in grouped.items():
                if len(group_dets) >= 2:  # è‡³å°‘éœ€è¦ 2 å¹€æ‰ç®—ä¸€å€‹äº‹ä»¶
                    # ä¿å­˜äº‹ä»¶å¹€
                    event_dir = session_dir / f"event_{group_id}"
                    event_dir.mkdir(exist_ok=True)
                    
                    frames = []
                    for i, det in enumerate(group_dets):
                        # ä¿å­˜è£åˆ‡åœ–ç‰‡
                        crop_path = event_dir / f"crop_{i:03d}_{det['timestamp']:.1f}s.jpg"
                        cv2.imwrite(str(crop_path), det['crop'])
                        
                        # åœ¨å®Œæ•´ç•«é¢ä¸Šç¹ªè£½æ¡†ç·š
                        full_frame = det['full_frame'].copy()
                        x1, y1, x2, y2 = [int(v) for v in det['bbox']]
                        cv2.rectangle(full_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(full_frame, f"Conf: {det['confidence']:.2f}", 
                                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                        
                        # ä¿å­˜å¸¶æ¡†ç·šçš„å®Œæ•´ç•«é¢
                        full_path = event_dir / f"full_{i:03d}_{det['timestamp']:.1f}s.jpg"
                        cv2.imwrite(str(full_path), full_frame)
                        
                        frames.append({
                            'crop_path': str(crop_path),
                            'full_path': str(full_path),
                            'image_path': str(crop_path),  # ä¿æŒç›¸å®¹æ€§
                            'timestamp': det['timestamp'],
                            'confidence': det['confidence'],
                            'bbox': det['bbox'],
                            'video_name': det.get('video_name', 'unknown'),
                            'video_idx': det.get('video_idx', 0)
                        })
                    
                    # ç²å–ä¸»è¦å½±ç‰‡ä¾†æº
                    video_names = list(set(det.get('video_name', 'unknown') for det in group_dets))
                    primary_video = video_names[0] if len(video_names) == 1 else 'multiple'
                    
                    event = {
                        'id': group_id,
                        'frames': frames,
                        'start_time': float(group_dets[0]['timestamp']),
                        'end_time': float(group_dets[-1]['timestamp']),
                        'duration': float(group_dets[-1]['timestamp'] - group_dets[0]['timestamp']),
                        'frame_count': len(group_dets),
                        'avg_confidence': float(np.mean([d['confidence'] for d in group_dets])),
                        'video_name': primary_video,
                        'video_names': video_names,
                        'label': None  # å¾…æ¨™è¨»
                    }
                    events.append(event)
            
            return events
        except Exception as e:
            print(f"åˆ†çµ„åµæ¸¬çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def label_event(self, event_idx, label):
        """æ¨™è¨»äº‹ä»¶"""
        if 0 <= event_idx < len(self.current_events):
            self.current_events[event_idx]['label'] = label
            self.current_events[event_idx]['labeled_at'] = datetime.now().isoformat()
            
            event = self.current_events[event_idx]
            
            # çµ±è¨ˆå·²æ¨™è¨»å’Œæœªæ¨™è¨»çš„æ•¸é‡
            labeled_count = sum(1 for e in self.current_events if e['label'] is not None)
            total_count = len(self.current_events)
            
            return f"äº‹ä»¶ {event_idx+1} å·²æ¨™è¨»ç‚ºï¼š{label}   é€²åº¦ï¼š{labeled_count}/{total_count}"
        return "æ¨™è¨»å¤±æ•—"
    
    def export_dataset(self):
        """åŒ¯å‡ºæ¨™è¨»å¥½çš„è³‡æ–™é›†"""
        if not self.current_events:
            return None, "å°šæœªåˆ†æå½±ç‰‡"
        
        labeled_events = [e for e in self.current_events if e['label'] is not None]
        if not labeled_events:
            return None, "å°šæœªæ¨™è¨»ä»»ä½•äº‹ä»¶"
        
        # å‰µå»ºè³‡æ–™é›†çµæ§‹
        export_dir = self.dataset_dir / f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        export_dir.mkdir(exist_ok=True)
        
        # æŒ‰æ¨™ç±¤åˆ†é¡
        true_positive_dir = export_dir / "true_positive"  # çœŸå¯¦ç«ç…™
        false_positive_dir = export_dir / "false_positive"  # èª¤åˆ¤
        true_positive_dir.mkdir(exist_ok=True)
        false_positive_dir.mkdir(exist_ok=True)
        
        stats = {'true_positive': 0, 'false_positive': 0}
        
        for event in labeled_events:
            if event['label'] == 'çœŸå¯¦ç«ç…™':
                target_dir = true_positive_dir
                stats['true_positive'] += 1
            else:  # 'èª¤åˆ¤'
                target_dir = false_positive_dir
                stats['false_positive'] += 1
            
            # è¤‡è£½äº‹ä»¶æª”æ¡ˆ
            event_target_dir = target_dir / f"event_{event['id']}"
            event_target_dir.mkdir(exist_ok=True)
            
            for frame in event['frames']:
                src_path = Path(frame['image_path'])
                if src_path.exists():
                    dst_path = event_target_dir / src_path.name
                    cv2.imwrite(str(dst_path), cv2.imread(str(src_path)))
            
            # ä¿å­˜äº‹ä»¶å…ƒè³‡æ–™ï¼ˆè½‰æ› numpy é¡å‹ç‚º Python åŸç”Ÿé¡å‹ï¼‰
            metadata = {
                'id': int(event['id']),
                'label': event['label'],
                'start_time': float(event['start_time']),
                'end_time': float(event['end_time']),
                'duration': float(event['duration']),
                'frame_count': int(event['frame_count']),
                'avg_confidence': float(event['avg_confidence']),
                'labeled_at': event.get('labeled_at')
            }
            
            with open(event_target_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜çµ±è¨ˆè³‡è¨Š
        summary = {
            'export_date': datetime.now().isoformat(),
            'total_events': len(labeled_events),
            'true_positive_count': stats['true_positive'],
            'false_positive_count': stats['false_positive'],
            'unlabeled_count': len(self.current_events) - len(labeled_events)
        }
        
        with open(export_dir / "dataset_summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        # å‰µå»º ZIP æª”æ¡ˆ
        zip_path = export_dir.with_suffix('.zip')
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for file_path in export_dir.rglob('*'):
                if file_path.is_file():
                    zipf.write(file_path, file_path.relative_to(export_dir))
        
        result_text = f"""
è³‡æ–™é›†åŒ¯å‡ºå®Œæˆï¼
çœŸå¯¦ç«ç…™ï¼š{stats['true_positive']} å€‹äº‹ä»¶
èª¤åˆ¤ï¼š{stats['false_positive']} å€‹äº‹ä»¶
æª”æ¡ˆä½ç½®ï¼š{zip_path}
        """.strip()
        
        return str(zip_path), result_text

def create_interface():
    analyzer = VideoAnalyzer()
    
    with gr.Blocks(title="ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ”¥ ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±")
        gr.Markdown("ä¸Šå‚³å¤šå€‹å½±ç‰‡ â†’ æ‰¹æ¬¡åˆ†æç«ç…™äº‹ä»¶ â†’ çµ±ä¸€æ¨™è¨»çœŸå¯¦/èª¤åˆ¤ â†’ åŒ¯å‡ºè¨“ç·´è³‡æ–™é›†")
        
        # ç‹€æ…‹è®Šæ•¸
        current_event_idx = gr.State(0)
        frame_idx = gr.State(0)
        
        with gr.Row():
            with gr.Column(scale=1):
                video_input = gr.File(
                    label="ä¸Šå‚³å½±ç‰‡æª”æ¡ˆï¼ˆæ”¯æ´å¤šæª”æ¡ˆï¼‰",
                    file_count="multiple",
                    file_types=[".mp4", ".mov", ".avi", ".mkv", ".webm"]
                )
                analyze_btn = gr.Button("ğŸ” é–‹å§‹åˆ†æ", variant="primary")
                
                analysis_result = gr.Textbox(
                    label="åˆ†æçµæœ",
                    lines=10,
                    placeholder="ä¸Šå‚³å½±ç‰‡æª”æ¡ˆï¼ˆæ”¯æ´å¤šå€‹æª”æ¡ˆï¼‰ä¸¦é»æ“Šåˆ†ææŒ‰éˆ•"
                )
                
            with gr.Column(scale=2):
                # ç•¶å‰äº‹ä»¶é¡¯ç¤ºå€
                gr.Markdown("## ğŸ¯ ç•¶å‰äº‹ä»¶")
                current_event_info = gr.Textbox(
                    label="äº‹ä»¶è³‡è¨Š",
                    lines=2,
                    interactive=False
                )
                
                with gr.Row():
                    # å·¦é‚Šï¼šå®Œæ•´ç•«é¢èˆ‡æ¡†ç·š
                    full_frame_display = gr.Image(
                        label="å®Œæ•´ç•«é¢ï¼ˆå«åµæ¸¬æ¡†ç·šï¼‰",
                        type="filepath",
                        height=400,
                        scale=2
                    )
                    
                    # å³é‚Šï¼šè£åˆ‡å€åŸŸè¼ªæ’­
                    crop_frame_display = gr.Image(
                        label="äº‹ä»¶å€åŸŸï¼ˆæ”¾å¤§æª¢è¦–ï¼‰",
                        type="filepath",
                        height=400,
                        scale=1
                    )
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("## ğŸ“ å¿«é€Ÿæ¨™è¨»")
                progress_info = gr.Textbox(
                    label="æ¨™è¨»é€²åº¦",
                    value="ç­‰å¾…åˆ†æå®Œæˆ...",
                    lines=2,
                    interactive=False
                )
                
                with gr.Row():
                    label_true_btn = gr.Button("âœ… çœŸå¯¦ç«ç…™", variant="primary", scale=1)
                    label_false_btn = gr.Button("âŒ èª¤åˆ¤", variant="secondary", scale=1)
                
                with gr.Row():
                    prev_btn = gr.Button("â¬…ï¸ ä¸Šä¸€å€‹", scale=1)
                    next_btn = gr.Button("â¡ï¸ ä¸‹ä¸€å€‹", scale=1)
                    skip_btn = gr.Button("â­ï¸ è·³é", scale=1)
                
            with gr.Column():
                gr.Markdown("## ğŸ“¦ åŒ¯å‡ºè³‡æ–™é›†")
                export_btn = gr.Button("ğŸ’¾ åŒ¯å‡ºæ¨™è¨»è³‡æ–™é›†", variant="secondary")
                export_result = gr.Textbox(label="åŒ¯å‡ºçµæœ", lines=3)
                export_file = gr.File(label="ä¸‹è¼‰è³‡æ–™é›†")
        
        # è‡ªå‹•è¼ªæ’­è¨ˆæ™‚å™¨
        timer = gr.Timer(value=0.5, active=False)
        
        # æ›´æ–°ç•¶å‰äº‹ä»¶é¡¯ç¤º
        def update_event_display(event_idx, frame_idx):
            try:
                if not analyzer.current_events or event_idx >= len(analyzer.current_events):
                    return "ç„¡äº‹ä»¶", None, None, f"é€²åº¦: 0/0", event_idx, 0
                
                event = analyzer.current_events[event_idx]
                if not event['frames']:
                    return "ç„¡å¹€è³‡æ–™", None, None, f"é€²åº¦: {event_idx+1}/{len(analyzer.current_events)}", event_idx, 0
                
                # å¾ªç’°é¡¯ç¤ºå¹€
                frame_idx = frame_idx % len(event['frames'])
                frame_info = event['frames'][frame_idx]
                
                # äº‹ä»¶è³‡è¨Š
                info_text = f"äº‹ä»¶ {event_idx+1}/{len(analyzer.current_events)} | " \
                           f"æ™‚é•·: {event['duration']:.1f}ç§’ | " \
                           f"å¹€æ•¸: {event['frame_count']} | " \
                           f"ä¿¡å¿ƒåº¦: {event['avg_confidence']:.2f}"
                
                # é¡¯ç¤ºå½±ç‰‡ä¾†æº
                if 'video_name' in event and event['video_name'] != 'multiple':
                    info_text += f" | ä¾†æº: {event['video_name']}"
                elif 'video_names' in event and len(event['video_names']) > 1:
                    info_text += f" | ä¾†æº: {len(event['video_names'])} å€‹å½±ç‰‡"
                
                if event['label']:
                    info_text += f" | å·²æ¨™è¨»: {event['label']}"
                
                # é€²åº¦è³‡è¨Š
                labeled_count = sum(1 for e in analyzer.current_events if e['label'] is not None)
                progress_text = f"é€²åº¦: {labeled_count}/{len(analyzer.current_events)} å·²æ¨™è¨»"
                
                # è¿”å›å®Œæ•´ç•«é¢å’Œè£åˆ‡å€åŸŸ
                full_path = frame_info.get('full_path', frame_info['image_path'])
                crop_path = frame_info.get('crop_path', frame_info['image_path'])
                
                return info_text, full_path, crop_path, progress_text, event_idx, (frame_idx + 1)
            except Exception as e:
                print(f"æ›´æ–°äº‹ä»¶é¡¯ç¤ºæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                return "éŒ¯èª¤", None, None, "éŒ¯èª¤", 0, 0
        
        # æ¨™è¨»ä¸¦ç§»åˆ°ä¸‹ä¸€å€‹
        def label_and_next(event_idx, label):
            if 0 <= event_idx < len(analyzer.current_events):
                analyzer.current_events[event_idx]['label'] = label
                analyzer.current_events[event_idx]['labeled_at'] = datetime.now().isoformat()
                
                # æ‰¾ä¸‹ä¸€å€‹æœªæ¨™è¨»çš„äº‹ä»¶
                next_idx = event_idx + 1
                while next_idx < len(analyzer.current_events):
                    if analyzer.current_events[next_idx]['label'] is None:
                        break
                    next_idx += 1
                
                if next_idx >= len(analyzer.current_events):
                    # å¦‚æœæ²’æœ‰æœªæ¨™è¨»çš„ï¼Œå›åˆ°ç¬¬ä¸€å€‹æœªæ¨™è¨»çš„
                    for i in range(len(analyzer.current_events)):
                        if analyzer.current_events[i]['label'] is None:
                            next_idx = i
                            break
                    else:
                        next_idx = 0  # å…¨éƒ¨éƒ½æ¨™è¨»å®Œäº†
                
                return next_idx, 0
            return event_idx, 0
        
        # å°èˆªå‡½æ•¸
        def go_prev(event_idx):
            new_idx = max(0, event_idx - 1)
            return new_idx, 0
        
        def go_next(event_idx):
            new_idx = min(len(analyzer.current_events) - 1, event_idx + 1) if analyzer.current_events else 0
            return new_idx, 0
        
        def skip_current(event_idx):
            return label_and_next(event_idx, None)[0], 0
        
        # è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ
        def process_uploaded_files(files):
            if not files:
                return "è«‹ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ", [], ""
            
            # æå–æª”æ¡ˆè·¯å¾‘
            video_paths = [file.name for file in files] if isinstance(files, list) else [files.name]
            return analyzer.analyze_videos(video_paths)
        
        # åˆ†æå½±ç‰‡å®Œæˆå¾Œçš„è™•ç†
        def on_analysis_complete(result, gallery, status):
            if analyzer.current_events:
                # å•Ÿå‹•è¨ˆæ™‚å™¨é–‹å§‹è¼ªæ’­
                return result, 0, 0, gr.Timer(active=True)
            return result, 0, 0, gr.Timer(active=False)
        
        # åˆ†æå½±ç‰‡
        analyze_btn.click(
            process_uploaded_files,
            inputs=[video_input],
            outputs=[analysis_result, gr.Gallery(visible=False), gr.Textbox(visible=False)]
        ).then(
            on_analysis_complete,
            inputs=[analysis_result, gr.Gallery(visible=False), gr.Textbox(visible=False)],
            outputs=[analysis_result, current_event_idx, frame_idx, timer]
        )
        
        # è¨ˆæ™‚å™¨è§¸ç™¼æ›´æ–°
        timer.tick(
            update_event_display,
            inputs=[current_event_idx, frame_idx],
            outputs=[current_event_info, full_frame_display, crop_frame_display, progress_info, current_event_idx, frame_idx]
        )
        
        # æ¨™è¨»äº‹ä»¶
        label_true_btn.click(
            lambda idx: label_and_next(idx, "çœŸå¯¦ç«ç…™"),
            inputs=[current_event_idx],
            outputs=[current_event_idx, frame_idx]
        )
        
        label_false_btn.click(
            lambda idx: label_and_next(idx, "èª¤åˆ¤"),
            inputs=[current_event_idx],
            outputs=[current_event_idx, frame_idx]
        )
        
        # å°èˆªæŒ‰éˆ•
        prev_btn.click(go_prev, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        next_btn.click(go_next, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        skip_btn.click(skip_current, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        
        # åŒ¯å‡ºè³‡æ–™é›†
        def export_and_return_file():
            zip_path, result_text = analyzer.export_dataset()
            return result_text, zip_path
        
        export_btn.click(
            export_and_return_file,
            outputs=[export_result, export_file]
        )
    
    return app

if __name__ == "__main__":
    print("ğŸ”¥ å•Ÿå‹•ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±...")
    print("=" * 50)
    print("åŠŸèƒ½ï¼š")
    print("âœ… å¤šå½±ç‰‡æ‰¹æ¬¡ä¸Šå‚³å’Œåˆ†æ")
    print("âœ… ä½¿ç”¨ best.pt é€²è¡Œç«ç…™åµæ¸¬")
    print("âœ… ReID æŠ€è¡“è‡ªå‹•åˆ†çµ„äº‹ä»¶")
    print("âœ… çµ±ä¸€æ¨™è¨»æµç¨‹è™•ç†å¤šå½±ç‰‡äº‹ä»¶")
    print("âœ… å¿«é€Ÿæ¨™è¨»çœŸå¯¦/èª¤åˆ¤")
    print("âœ… åŒ¯å‡ºçµæ§‹åŒ–è¨“ç·´è³‡æ–™é›†")
    print("=" * 50)
    
    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )