#!/usr/bin/env python3
"""
ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±
ä¸Šå‚³å½±ç‰‡å¾Œä½¿ç”¨ best.pt æ¨¡å‹æƒæï¼ŒæŒ‰ ReID åˆ†çµ„äº‹ä»¶ï¼Œå¿«é€Ÿæ¨™è¨»æœ‰/ç„¡èª¤åˆ¤
"""

import gradio as gr
import cv2
import numpy as np
from pathlib import Path
import json
import uuid
from datetime import datetime
import tempfile
import os
from collections import defaultdict
import zipfile
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("âš ï¸  Ultralytics æœªå®‰è£ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬åµæ¸¬")

try:
    import supervision as sv
    SUPERVISION_AVAILABLE = True
except ImportError:
    SUPERVISION_AVAILABLE = False
    print("âš ï¸  Supervision æœªå®‰è£ï¼ŒReID åŠŸèƒ½å—é™")

try:
    import psutil
    import gc
    MEMORY_MONITORING_AVAILABLE = True
except ImportError:
    MEMORY_MONITORING_AVAILABLE = False
    print("âš ï¸  psutil æœªå®‰è£ï¼Œè¨˜æ†¶é«”ç›£æ§åŠŸèƒ½å—é™")

class VideoAnalyzer:
    def __init__(self):
        self.model_path = "best.pt"
        self.work_dir = Path("temp_analysis")
        self.work_dir.mkdir(exist_ok=True)
        self.dataset_dir = Path("dataset")
        self.dataset_dir.mkdir(exist_ok=True)
        
        # é€²åº¦è¿½è¹¤
        self.progress_queue = queue.Queue()
        self.analysis_status = {}
        self.max_workers = min(4, os.cpu_count() or 1)  # é™åˆ¶ä¸¦ç™¼æ•¸
        
        # æª¢æ¸¬å¯ç”¨è¨­å‚™
        self.available_devices = self._detect_available_devices()
        self.current_device = self.available_devices['default']
        
        # å»¶é²æ¨¡å‹è¼‰å…¥ï¼Œç­‰å¾…ç”¨æˆ¶é¸æ“‡è¨­å‚™
        self.model = None
        
        # åˆå§‹åŒ–è¿½è¹¤å™¨
        if SUPERVISION_AVAILABLE:
            self.tracker = sv.ByteTrack()
        else:
            self.tracker = None
        
        self.current_events = []
        self.session_id = None
        
        # è¨˜æ†¶é«”ç®¡ç†
        self._cleanup_old_sessions()
    
    def _detect_available_devices(self):
        """æª¢æ¸¬å¯ç”¨çš„è¨ˆç®—è¨­å‚™"""
        devices = {
            'options': ['cpu'],
            'default': 'cpu',
            'status': {'cpu': 'âœ… å¯ç”¨'}
        }
        
        if ULTRALYTICS_AVAILABLE:
            try:
                import torch
                
                # æª¢æŸ¥ CUDA
                if torch.cuda.is_available():
                    devices['options'].insert(0, 'cuda')
                    devices['default'] = 'cuda'
                    device_name = torch.cuda.get_device_name()
                    devices['status']['cuda'] = f'âœ… å¯ç”¨ ({device_name})'
                    print(f"âœ… æª¢æ¸¬åˆ° CUDA: {device_name}")
                else:
                    devices['status']['cuda'] = 'âŒ ä¸å¯ç”¨'
                
                # æª¢æŸ¥ MPS (Apple Silicon)
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    if 'cuda' not in devices['options']:  # å¦‚æœæ²’æœ‰ CUDAï¼ŒMPS ç‚ºå„ªå…ˆ
                        devices['options'].insert(0, 'mps')
                        devices['default'] = 'mps'
                    else:
                        devices['options'].insert(1, 'mps')
                    devices['status']['mps'] = 'âœ… å¯ç”¨ (Apple Silicon)'
                    print("âœ… æª¢æ¸¬åˆ° MPS (Apple Silicon)")
                else:
                    devices['status']['mps'] = 'âŒ ä¸å¯ç”¨'
                    
            except Exception as e:
                print(f"è¨­å‚™æª¢æ¸¬éŒ¯èª¤: {e}")
        
        print(f"å¯ç”¨è¨­å‚™: {devices['options']}, é è¨­: {devices['default']}")
        return devices
    
    def load_model(self, device='auto'):
        """è¼‰å…¥æˆ–é‡æ–°è¼‰å…¥æ¨¡å‹åˆ°æŒ‡å®šè¨­å‚™"""
        if device == 'auto':
            device = self.current_device
        
        try:
            if ULTRALYTICS_AVAILABLE and Path(self.model_path).exists():
                print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹åˆ° {device}...")
                
                # é‡‹æ”¾èˆŠæ¨¡å‹
                if self.model is not None:
                    del self.model
                    if MEMORY_MONITORING_AVAILABLE:
                        gc.collect()
                
                self.model = YOLO(self.model_path)
                self.model.to(device)
                self.current_device = device
                print(f"âœ… å·²è¼‰å…¥ best.pt æ¨¡å‹åˆ° {device}")
                return f"âœ… æ¨¡å‹å·²è¼‰å…¥åˆ° {device}"
            else:
                self.model = None
                print("âš ï¸  æœªæ‰¾åˆ° best.ptï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬åµæ¸¬")
                return "âš ï¸  æœªæ‰¾åˆ° best.ptï¼Œä½¿ç”¨æ¨¡æ“¬åµæ¸¬"
        except Exception as e:
            print(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            # å›é€€åˆ° CPU
            if device != 'cpu':
                print("å˜—è©¦å›é€€åˆ° CPU...")
                return self.load_model('cpu')
            else:
                self.model = None
                return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}"
        
        # è¨˜æ†¶é«”ç®¡ç†
        self._cleanup_old_sessions()
    
    def analyze_videos(self, video_paths, confidence_threshold=0.300, progress_callback=None):
        """åˆ†æå¤šå€‹å½±ç‰‡ï¼Œæå–äº‹ä»¶ï¼ˆæ”¯æ´ä¸¦ç™¼è™•ç†ï¼‰"""
        try:
            if not video_paths:
                return "è«‹ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ", [], ""
            
            # ç¢ºä¿æ˜¯ä¸²åˆ—
            if not isinstance(video_paths, list):
                video_paths = [video_paths]
            
            self.session_id = str(uuid.uuid4())[:8]
            session_dir = self.work_dir / self.session_id
            session_dir.mkdir(exist_ok=True)
            
            # åˆå§‹åŒ–é€²åº¦è¿½è¹¤
            self.analysis_status = {}
            for i, path in enumerate(video_paths):
                video_name = Path(path).name
                self.analysis_status[i] = {
                    'name': video_name,
                    'status': 'ç­‰å¾…ä¸­',
                    'progress': 0,
                    'detections': 0
                }
            
            all_video_detections = []
            video_summaries = []
            
            print(f"æº–å‚™ä¸¦ç™¼åˆ†æ {len(video_paths)} å€‹å½±ç‰‡ï¼ˆæœ€å¤š {self.max_workers} å€‹ä¸¦ç™¼ï¼‰...")
            
            if progress_callback:
                progress_callback(self._format_progress_text())
            
            # ä½¿ç”¨ç·šç¨‹æ± ä¸¦ç™¼è™•ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»å‹™
                future_to_video = {
                    executor.submit(self._analyze_single_video_with_progress, video_path, video_idx, Path(video_path).name, confidence_threshold, progress_callback): (video_idx, video_path)
                    for video_idx, video_path in enumerate(video_paths)
                }
                
                # æ”¶é›†çµæœ
                for future in as_completed(future_to_video):
                    video_idx, video_path = future_to_video[future]
                    try:
                        video_detections, summary = future.result()
                        video_summaries.append(summary)
                        all_video_detections.extend(video_detections)
                        
                        # æ›´æ–°ç‹€æ…‹
                        self.analysis_status[video_idx]['status'] = 'å®Œæˆ'
                        if progress_callback:
                            progress_callback(self._format_progress_text())
                            
                    except Exception as e:
                        print(f"åˆ†æå½±ç‰‡ {Path(video_path).name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                        self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
                        self.analysis_status[video_idx]['error'] = str(e)
                        if progress_callback:
                            progress_callback(self._format_progress_text())
            
            print(f"\nç¸½å…±åµæ¸¬åˆ° {len(all_video_detections)} å€‹ç‰©ä»¶ï¼Œé–‹å§‹åˆ†çµ„...")
            if progress_callback:
                progress_callback(self._format_progress_text() + "\n\nğŸ”„ æ­£åœ¨åˆ†çµ„äº‹ä»¶...")
            
            # æŒ‰ ReID åˆ†çµ„äº‹ä»¶
            events = self._group_detections_by_reid(all_video_detections, session_dir)
            
            print(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶")
            
            self.current_events = events
            
            # ç”Ÿæˆåˆ†æçµæœ
            result_text = f"""
åˆ†æå®Œæˆï¼
å½±ç‰‡æ•¸é‡ï¼š{len(video_paths)} å€‹
"""
            for summary in video_summaries:
                result_text += f"\n{summary['name']}: {summary['detections']} å€‹åµæ¸¬, {summary['duration']:.1f} ç§’"
            
            result_text += f"""

ç¸½åµæ¸¬æ•¸ï¼š{len(all_video_detections)} å€‹
åˆ†çµ„äº‹ä»¶æ•¸ï¼š{len(events)} å€‹

ä½¿ç”¨ä¸Šæ–¹è¼ªæ’­ä»‹é¢é€²è¡Œæ¨™è¨»
            """.strip()
            
            # ç”Ÿæˆäº‹ä»¶ç¸®åœ–ä¾›é¸æ“‡
            event_gallery = []
            for i, event in enumerate(events):
                if event['frames']:
                    # ä½¿ç”¨ç¬¬ä¸€å¹€ä½œç‚ºä»£è¡¨åœ–åƒ
                    first_frame_path = event['frames'][0]['image_path']
                    event_gallery.append(first_frame_path)
            
            return result_text, event_gallery, f"æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶"
            
        except Exception as e:
            print(f"åˆ†æå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"åˆ†æå¤±æ•—: {str(e)}", [], "éŒ¯èª¤"
    
    def _analyze_single_video(self, video_path, video_idx, video_name):
        """åˆ†æå–®å€‹å½±ç‰‡"""
        # æ‰“é–‹å½±ç‰‡
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"ç„¡æ³•æ‰“é–‹å½±ç‰‡æª”æ¡ˆ: {video_name}")
            return [], {'name': video_name, 'detections': 0, 'duration': 0}
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        print(f"å½±ç‰‡è³‡è¨Š: {total_frames} å¹€, {fps:.1f} FPS, {duration:.1f} ç§’")
        
        # æ”¶é›†åµæ¸¬çµæœ
        video_detections = []
        frame_idx = 0
        sample_interval = max(1, int(fps * 1.0))  # æ¯ 1 ç§’æ¡æ¨£ä¸€å¹€
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_idx % 100 == 0:  # æ¯ 100 å¹€é¡¯ç¤ºé€²åº¦
                print(f"åˆ†æé€²åº¦: {frame_idx}/{total_frames} å¹€ ({frame_idx/total_frames*100:.1f}%)")
            
            # æ¡æ¨£ç­–ç•¥ï¼šæ¯ç§’å–ä¸€å¹€
            if frame_idx % sample_interval == 0:
                timestamp = frame_idx / fps
                detections = self._detect_objects(frame, frame_idx, timestamp, confidence_threshold)
                if detections:
                    # åŠ ä¸Šå½±ç‰‡ä¾†æºè³‡è¨Š
                    for det in detections:
                        det['video_name'] = video_name
                        det['video_idx'] = video_idx
                    video_detections.extend(detections)
            
            frame_idx += 1
            
            # é‡‹æ”¾è¨˜æ†¶é«”
            if frame_idx % 500 == 0 and MEMORY_MONITORING_AVAILABLE:
                gc.collect()
        
        cap.release()
        
        summary = {
            'name': video_name,
            'detections': len(video_detections),
            'duration': duration
        }
        
        return video_detections, summary
    
    def _analyze_single_video_with_progress(self, video_path, video_idx, video_name, confidence_threshold, progress_callback):
        """å¸¶é€²åº¦å›é¥‹çš„å–®å€‹å½±ç‰‡åˆ†æ"""
        try:
            # æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
            self.analysis_status[video_idx]['status'] = 'è™•ç†ä¸­'
            if progress_callback:
                progress_callback(self._format_progress_text())
            
            # æ‰“é–‹å½±ç‰‡
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
                self.analysis_status[video_idx]['error'] = 'ç„¡æ³•æ‰“é–‹å½±ç‰‡'
                return [], {'name': video_name, 'detections': 0, 'duration': 0}
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # æ”¶é›†åµæ¸¬çµæœ
            video_detections = []
            frame_idx = 0
            sample_interval = max(1, int(fps * 1.0))
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ›´æ–°é€²åº¦
                progress_percent = int((frame_idx / total_frames) * 100) if total_frames > 0 else 0
                self.analysis_status[video_idx]['progress'] = progress_percent
                
                # æ¯100å¹€æˆ–é€²åº¦è®ŠåŒ–æ™‚æ›´æ–°ä»‹é¢
                if frame_idx % 100 == 0 or progress_percent != self.analysis_status[video_idx].get('last_progress', -1):
                    self.analysis_status[video_idx]['last_progress'] = progress_percent
                    if progress_callback:
                        progress_callback(self._format_progress_text())
                
                # æ¡æ¨£ç­–ç•¥ï¼šæ¯ç§’å–ä¸€å¹€
                if frame_idx % sample_interval == 0:
                    timestamp = frame_idx / fps
                    detections = self._detect_objects(frame, frame_idx, timestamp, confidence_threshold)
                    if detections:
                        # åŠ ä¸Šå½±ç‰‡ä¾†æºè³‡è¨Š
                        for det in detections:
                            det['video_name'] = video_name
                            det['video_idx'] = video_idx
                        video_detections.extend(detections)
                        
                        # æ›´æ–°åµæ¸¬æ•¸é‡
                        self.analysis_status[video_idx]['detections'] = len(video_detections)
                
                frame_idx += 1
                
                # é‡‹æ”¾è¨˜æ†¶é«”å’Œå„ªåŒ–
                if frame_idx % 500 == 0:
                    memory_usage = self._optimize_memory_usage()
                    if frame_idx % 1000 == 0:  # æ¯1000å¹€é¡¯ç¤ºä¸€æ¬¡è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
                        print(f"è¨˜æ†¶é«”ä½¿ç”¨: {memory_usage:.1f} MB")
            
            cap.release()
            
            # å®Œæˆç‹€æ…‹
            self.analysis_status[video_idx]['progress'] = 100
            self.analysis_status[video_idx]['detections'] = len(video_detections)
            
            summary = {
                'name': video_name,
                'detections': len(video_detections),
                'duration': duration
            }
            
            return video_detections, summary
            
        except Exception as e:
            self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
            self.analysis_status[video_idx]['error'] = str(e)
            if progress_callback:
                progress_callback(self._format_progress_text())
            raise e
    
    def _format_progress_text(self):
        """æ ¼å¼åŒ–é€²åº¦æ–‡å­—"""
        lines = [f"ğŸ“Š åˆ†æé€²åº¦ ({len(self.analysis_status)} å€‹å½±ç‰‡):"]
        lines.append("")
        
        for idx, status in self.analysis_status.items():
            name = status['name'][:30] + "..." if len(status['name']) > 30 else status['name']
            
            if status['status'] == 'ç­‰å¾…ä¸­':
                lines.append(f"â³ {name}: ç­‰å¾…ä¸­")
            elif status['status'] == 'è™•ç†ä¸­':
                progress = status.get('progress', 0)
                detections = status.get('detections', 0)
                lines.append(f"ğŸ”„ {name}: {progress}% ({detections} å€‹åµæ¸¬)")
            elif status['status'] == 'å®Œæˆ':
                detections = status.get('detections', 0)
                lines.append(f"âœ… {name}: å®Œæˆ ({detections} å€‹åµæ¸¬)")
            elif status['status'] == 'éŒ¯èª¤':
                error = status.get('error', 'æœªçŸ¥éŒ¯èª¤')
                lines.append(f"âŒ {name}: éŒ¯èª¤ - {error}")
        
        return "\n".join(lines)
    
    def _cleanup_old_sessions(self):
        """æ¸…ç†èˆŠçš„åˆ†ææœƒè©±ä»¥ç¯€çœç£ç¢Ÿç©ºé–“"""
        try:
            if not self.work_dir.exists():
                return
                
            import time
            current_time = time.time()
            
            for session_path in self.work_dir.iterdir():
                if session_path.is_dir():
                    # æª¢æŸ¥è³‡æ–™å¤¾ä¿®æ”¹æ™‚é–“ï¼Œåˆªé™¤è¶…é1å°æ™‚çš„èˆŠæœƒè©±
                    if current_time - session_path.stat().st_mtime > 3600:  # 1å°æ™‚
                        import shutil
                        shutil.rmtree(session_path, ignore_errors=True)
                        print(f"æ¸…ç†èˆŠæœƒè©±: {session_path.name}")
        except Exception as e:
            print(f"æ¸…ç†èˆŠæœƒè©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _optimize_memory_usage(self):
        """å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"""
        if not MEMORY_MONITORING_AVAILABLE:
            return 0
            
        try:
            # å¼·åˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            process = psutil.Process(os.getpid())
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            
            if memory_usage > 2000:  # å¦‚æœè¶…é2GB
                print(f"âš ï¸  è¨˜æ†¶é«”ä½¿ç”¨é‡è¼ƒé«˜: {memory_usage:.1f} MB")
                # æ¸…ç†å¯èƒ½çš„å¤§å‹è®Šæ•¸
                gc.collect()
                
            return memory_usage
        except Exception as e:
            print(f"è¨˜æ†¶é«”ç›£æ§éŒ¯èª¤: {e}")
            return 0
    
    def _detect_objects(self, frame, frame_idx, timestamp, confidence_threshold=0.300):
        """åœ¨å¹€ä¸­åµæ¸¬ç‰©ä»¶"""
        try:
            if self.model:
                # ä½¿ç”¨çœŸå¯¦çš„ YOLO æ¨¡å‹ï¼ˆæœƒè‡ªå‹•ä½¿ç”¨å·²è¨­å®šçš„ deviceï¼‰
                results = self.model(frame, conf=confidence_threshold, verbose=False)
                detections = []
                
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            
                            # è£åˆ‡æª¢æ¸¬å€åŸŸ
                            crop = frame[int(y1):int(y2), int(x1):int(x2)]
                            if crop.size > 0:
                                detections.append({
                                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                    'confidence': float(conf),
                                    'class': int(cls),
                                    'frame_idx': frame_idx,
                                    'timestamp': timestamp,
                                    'crop': crop,
                                    'full_frame': frame.copy()  # ä¿å­˜å®Œæ•´ç•«é¢
                                })
                return detections
            else:
                # æ¨¡æ“¬åµæ¸¬ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
                h, w = frame.shape[:2]
                if frame_idx % 10 == 0:  # æ¯10å¹€æ¨¡æ“¬ä¸€å€‹åµæ¸¬
                    x1, y1 = w//4, h//4
                    x2, y2 = w*3//4, h*3//4
                    crop = frame[y1:y2, x1:x2]
                    return [{
                        'bbox': [x1, y1, x2, y2],
                        'confidence': 0.8,
                        'class': 0,
                        'frame_idx': frame_idx,
                        'timestamp': timestamp,
                        'crop': crop,
                        'full_frame': frame.copy()
                    }]
                return []
        except Exception as e:
            print(f"åµæ¸¬ç‰©ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def _group_detections_by_reid(self, detections, session_dir):
        """ä½¿ç”¨ ReID åˆ†çµ„åµæ¸¬çµæœ"""
        try:
            if not detections:
                return []
            
            # ç°¡åŒ–ç‰ˆåˆ†çµ„ï¼šæŒ‰ä½ç½®å’Œæ™‚é–“æ¥è¿‘åº¦åˆ†çµ„
            events = []
            grouped = defaultdict(list)
            
            for det in detections:
                # è¨ˆç®—ä¸­å¿ƒé»
                x1, y1, x2, y2 = det['bbox']
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                # æ‰¾åˆ°æœ€è¿‘çš„çµ„åˆ¥
                best_group = None
                min_distance = float('inf')
                
                for group_id, group_dets in grouped.items():
                    # è¨ˆç®—èˆ‡çµ„åˆ¥ä¸­æœ€å¾Œä¸€å€‹åµæ¸¬çš„è·é›¢
                    last_det = group_dets[-1]
                    last_x1, last_y1, last_x2, last_y2 = last_det['bbox']
                    last_center_x = (last_x1 + last_x2) / 2
                    last_center_y = (last_y1 + last_y2) / 2
                    
                    distance = np.sqrt((center_x - last_center_x)**2 + (center_y - last_center_y)**2)
                    time_diff = abs(det['timestamp'] - last_det['timestamp'])
                    
                    # å¦‚æœä½ç½®æ¥è¿‘ä¸”æ™‚é–“å·®ä¸å¤§ï¼Œè¦–ç‚ºåŒä¸€äº‹ä»¶
                    if distance < 100 and time_diff < 10:  # å¯èª¿æ•´çš„é–¾å€¼
                        if distance < min_distance:
                            min_distance = distance
                            best_group = group_id
                
                if best_group is not None:
                    grouped[best_group].append(det)
                else:
                    # å‰µå»ºæ–°çµ„åˆ¥
                    new_group_id = len(grouped)
                    grouped[new_group_id].append(det)
            
            # è½‰æ›ç‚ºäº‹ä»¶æ ¼å¼
            for group_id, group_dets in grouped.items():
                if len(group_dets) >= 2:  # è‡³å°‘éœ€è¦ 2 å¹€æ‰ç®—ä¸€å€‹äº‹ä»¶
                    # ä¿å­˜äº‹ä»¶å¹€
                    event_dir = session_dir / f"event_{group_id}"
                    event_dir.mkdir(exist_ok=True)
                    
                    frames = []
                    for i, det in enumerate(group_dets):
                        # ä¿å­˜è£åˆ‡åœ–ç‰‡
                        crop_path = event_dir / f"crop_{i:03d}_{det['timestamp']:.1f}s.jpg"
                        cv2.imwrite(str(crop_path), det['crop'])
                        
                        # åœ¨å®Œæ•´ç•«é¢ä¸Šç¹ªè£½æ¡†ç·š
                        full_frame = det['full_frame'].copy()
                        x1, y1, x2, y2 = [int(v) for v in det['bbox']]
                        cv2.rectangle(full_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(full_frame, f"Conf: {det['confidence']:.2f}", 
                                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                        
                        # ä¿å­˜å¸¶æ¡†ç·šçš„å®Œæ•´ç•«é¢
                        full_path = event_dir / f"full_{i:03d}_{det['timestamp']:.1f}s.jpg"
                        cv2.imwrite(str(full_path), full_frame)
                        
                        frames.append({
                            'crop_path': str(crop_path),
                            'full_path': str(full_path),
                            'image_path': str(crop_path),  # ä¿æŒç›¸å®¹æ€§
                            'timestamp': det['timestamp'],
                            'confidence': det['confidence'],
                            'bbox': det['bbox'],
                            'video_name': det.get('video_name', 'unknown'),
                            'video_idx': det.get('video_idx', 0)
                        })
                    
                    # ç²å–ä¸»è¦å½±ç‰‡ä¾†æº
                    video_names = list(set(det.get('video_name', 'unknown') for det in group_dets))
                    primary_video = video_names[0] if len(video_names) == 1 else 'multiple'
                    
                    event = {
                        'id': group_id,
                        'frames': frames,
                        'start_time': float(group_dets[0]['timestamp']),
                        'end_time': float(group_dets[-1]['timestamp']),
                        'duration': float(group_dets[-1]['timestamp'] - group_dets[0]['timestamp']),
                        'frame_count': len(group_dets),
                        'avg_confidence': float(np.mean([d['confidence'] for d in group_dets])),
                        'video_name': primary_video,
                        'video_names': video_names,
                        'label': None  # å¾…æ¨™è¨»
                    }
                    events.append(event)
            
            return events
        except Exception as e:
            print(f"åˆ†çµ„åµæ¸¬çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def label_event(self, event_idx, label):
        """æ¨™è¨»äº‹ä»¶"""
        if 0 <= event_idx < len(self.current_events):
            self.current_events[event_idx]['label'] = label
            self.current_events[event_idx]['labeled_at'] = datetime.now().isoformat()
            
            event = self.current_events[event_idx]
            
            # çµ±è¨ˆå·²æ¨™è¨»å’Œæœªæ¨™è¨»çš„æ•¸é‡
            labeled_count = sum(1 for e in self.current_events if e['label'] is not None)
            total_count = len(self.current_events)
            
            # çµ±è¨ˆæŒ‰å½±ç‰‡åˆ†çµ„çš„é€²åº¦
            video_progress = self._get_video_labeling_progress()
            
            # æ§‹å»ºè©³ç´°é€²åº¦ä¿¡æ¯
            progress_text = f"äº‹ä»¶ {event_idx+1} å·²æ¨™è¨»ç‚ºï¼š{label}\n"
            progress_text += f"ç¸½é«”é€²åº¦ï¼š{labeled_count}/{total_count} ({labeled_count/total_count*100:.1f}%)\n"
            progress_text += f"ä¾†æºæª”æ¡ˆï¼š{event.get('video_name', 'unknown')}\n"
            progress_text += video_progress
            
            return progress_text
        return "æ¨™è¨»å¤±æ•—"
    
    def _get_video_labeling_progress(self):
        """ç²å–æŒ‰å½±ç‰‡åˆ†çµ„çš„æ¨™è¨»é€²åº¦"""
        video_stats = {}
        
        # æŒ‰å½±ç‰‡çµ±è¨ˆäº‹ä»¶
        for i, event in enumerate(self.current_events):
            video_name = event.get('video_name', 'unknown')
            if video_name not in video_stats:
                video_stats[video_name] = {'total': 0, 'labeled': 0, 'events': []}
            
            video_stats[video_name]['total'] += 1
            video_stats[video_name]['events'].append(i)
            
            if event.get('label') is not None:
                video_stats[video_name]['labeled'] += 1
        
        # æ§‹å»ºé€²åº¦æ–‡æœ¬
        progress_lines = []
        completed_videos = 0
        
        for video_name, stats in video_stats.items():
            labeled = stats['labeled']
            total = stats['total']
            percentage = (labeled / total * 100) if total > 0 else 0
            
            status = "âœ… å®Œæˆ" if labeled == total else f"ğŸ“ é€²è¡Œä¸­"
            if labeled == total:
                completed_videos += 1
                
            progress_lines.append(f"  {status} {video_name}: {labeled}/{total} ({percentage:.0f}%)")
        
        total_videos = len(video_stats)
        summary = f"å½±ç‰‡é€²åº¦ï¼š{completed_videos}/{total_videos} å€‹æª”æ¡ˆå®Œæˆ\n"
        
        return summary + "\n".join(progress_lines)
    
    def export_dataset(self):
        """åŒ¯å‡ºæ¨™è¨»å¥½çš„è³‡æ–™é›†"""
        if not self.current_events:
            return None, "å°šæœªåˆ†æå½±ç‰‡"
        
        labeled_events = [e for e in self.current_events if e['label'] is not None]
        if not labeled_events:
            return None, "å°šæœªæ¨™è¨»ä»»ä½•äº‹ä»¶"
        
        # å‰µå»ºè³‡æ–™é›†çµæ§‹
        export_dir = self.dataset_dir / f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        export_dir.mkdir(exist_ok=True)
        
        # æŒ‰æ¨™ç±¤åˆ†é¡
        true_positive_dir = export_dir / "true_positive"  # çœŸå¯¦ç«ç…™
        false_positive_dir = export_dir / "false_positive"  # èª¤åˆ¤
        true_positive_dir.mkdir(exist_ok=True)
        false_positive_dir.mkdir(exist_ok=True)
        
        stats = {'true_positive': 0, 'false_positive': 0}
        
        for event in labeled_events:
            if event['label'] == 'çœŸå¯¦ç«ç…™':
                target_dir = true_positive_dir
                stats['true_positive'] += 1
            else:  # 'èª¤åˆ¤'
                target_dir = false_positive_dir
                stats['false_positive'] += 1
            
            # è¤‡è£½äº‹ä»¶æª”æ¡ˆ
            event_target_dir = target_dir / f"event_{event['id']}"
            event_target_dir.mkdir(exist_ok=True)
            
            for frame in event['frames']:
                src_path = Path(frame['image_path'])
                if src_path.exists():
                    dst_path = event_target_dir / src_path.name
                    cv2.imwrite(str(dst_path), cv2.imread(str(src_path)))
            
            # ä¿å­˜äº‹ä»¶å…ƒè³‡æ–™ï¼ˆè½‰æ› numpy é¡å‹ç‚º Python åŸç”Ÿé¡å‹ï¼‰
            metadata = {
                'id': int(event['id']),
                'label': event['label'],
                'start_time': float(event['start_time']),
                'end_time': float(event['end_time']),
                'duration': float(event['duration']),
                'frame_count': int(event['frame_count']),
                'avg_confidence': float(event['avg_confidence']),
                'labeled_at': event.get('labeled_at')
            }
            
            with open(event_target_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜çµ±è¨ˆè³‡è¨Š
        summary = {
            'export_date': datetime.now().isoformat(),
            'total_events': len(labeled_events),
            'true_positive_count': stats['true_positive'],
            'false_positive_count': stats['false_positive'],
            'unlabeled_count': len(self.current_events) - len(labeled_events)
        }
        
        with open(export_dir / "dataset_summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        # å‰µå»º ZIP æª”æ¡ˆ
        zip_path = export_dir.with_suffix('.zip')
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for file_path in export_dir.rglob('*'):
                if file_path.is_file():
                    zipf.write(file_path, file_path.relative_to(export_dir))
        
        result_text = f"""
è³‡æ–™é›†åŒ¯å‡ºå®Œæˆï¼
çœŸå¯¦ç«ç…™ï¼š{stats['true_positive']} å€‹äº‹ä»¶
èª¤åˆ¤ï¼š{stats['false_positive']} å€‹äº‹ä»¶
æª”æ¡ˆä½ç½®ï¼š{zip_path}
        """.strip()
        
        return str(zip_path), result_text

def create_interface():
    analyzer = VideoAnalyzer()
    
    with gr.Blocks(title="ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ”¥ ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±")
        gr.Markdown("ä¸Šå‚³å¤šå€‹å½±ç‰‡ â†’ æ‰¹æ¬¡åˆ†æç«ç…™äº‹ä»¶ â†’ çµ±ä¸€æ¨™è¨»çœŸå¯¦/èª¤åˆ¤ â†’ åŒ¯å‡ºè¨“ç·´è³‡æ–™é›†")
        
        # ç‹€æ…‹è®Šæ•¸
        current_event_idx = gr.State(0)
        frame_idx = gr.State(0)
        
        # ç‚º analyzer æ·»åŠ é€²åº¦è¿½è¹¤å±¬æ€§
        analyzer.current_progress = ""
        analyzer.analysis_complete = False
        analyzer.analysis_result = None
        analyzer.analysis_error = None
        
        # è¼‰å…¥æ¨¡å‹åˆ°æŒ‡å®šè¨­å‚™
        def load_model_to_device(device):
            status_message = analyzer.load_model(device)
            
            # åŒæ™‚é¡¯ç¤ºè¨­å‚™å¯ç”¨æ€§ä¿¡æ¯
            device_info = []
            for dev in ['cuda', 'mps', 'cpu']:
                if dev in analyzer.available_devices['status']:
                    status = analyzer.available_devices['status'][dev]
                    device_info.append(f"{dev.upper()}: {status}")
            
            full_status = f"{status_message}\n\nè¨­å‚™ç‹€æ…‹:\n" + "\n".join(device_info)
            return full_status
        
        # åˆå§‹è¼‰å…¥æ¨¡å‹åˆ°é è¨­è¨­å‚™
        initial_status = load_model_to_device(analyzer.available_devices['default'])
        
        with gr.Row():
            with gr.Column(scale=1):
                video_input = gr.File(
                    label="ä¸Šå‚³å½±ç‰‡æª”æ¡ˆï¼ˆæ”¯æ´å¤šæª”æ¡ˆï¼‰",
                    file_count="multiple",
                    file_types=[".mp4", ".mov", ".avi", ".mkv", ".webm"]
                )
                
                confidence_slider = gr.Slider(
                    minimum=0.001,
                    maximum=1.0,
                    value=0.300,
                    step=0.001,
                    label="ğŸ¯ åµæ¸¬ä¿¡å¿ƒåº¦é–¾å€¼",
                    info="èª¿æ•´YOLOæ¨¡å‹çš„åµæ¸¬é–¾å€¼ï¼Œæ•¸å€¼è¶Šä½åµæ¸¬è¶Šæ•æ„Ÿ"
                )
                
                with gr.Row():
                    device_dropdown = gr.Dropdown(
                        choices=analyzer.available_devices['options'],
                        value=analyzer.available_devices['default'],
                        label="âš¡ è¨ˆç®—è¨­å‚™",
                        info="é¸æ“‡æ¨¡å‹é‹è¡Œè¨­å‚™"
                    )
                    load_model_btn = gr.Button("ğŸ”„ è¼‰å…¥æ¨¡å‹", variant="secondary", size="sm")
                
                model_status = gr.Textbox(
                    label="ğŸ“Š æ¨¡å‹ç‹€æ…‹",
                    value=initial_status,
                    lines=4,
                    interactive=False
                )
                
                analyze_btn = gr.Button("ğŸ” é–‹å§‹åˆ†æ", variant="primary")
                
                # å³æ™‚é€²åº¦é¡¯ç¤º
                progress_display = gr.Textbox(
                    label="ğŸ“Š å³æ™‚åˆ†æé€²åº¦",
                    lines=8,
                    placeholder="ç­‰å¾…ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ...",
                    interactive=False,
                    max_lines=15
                )
                
                analysis_result = gr.Textbox(
                    label="åˆ†æçµæœ",
                    lines=6,
                    placeholder="åˆ†æå®Œæˆå¾Œé¡¯ç¤ºçµæœ",
                    interactive=False
                )
                
            with gr.Column(scale=2):
                # ç•¶å‰äº‹ä»¶é¡¯ç¤ºå€
                gr.Markdown("## ğŸ¯ ç•¶å‰äº‹ä»¶ & å¿«é€Ÿæ¨™è¨»")
                current_event_info = gr.Textbox(
                    label="äº‹ä»¶è³‡è¨Š",
                    lines=2,
                    interactive=False
                )
                
                with gr.Row():
                    # å·¦é‚Šï¼šå®Œæ•´ç•«é¢èˆ‡æ¡†ç·š
                    full_frame_display = gr.Image(
                        label="å®Œæ•´ç•«é¢ï¼ˆå«åµæ¸¬æ¡†ç·šï¼‰",
                        type="filepath",
                        height=400,
                        scale=2
                    )
                    
                    # å³é‚Šï¼šè£åˆ‡å€åŸŸè¼ªæ’­
                    crop_frame_display = gr.Image(
                        label="äº‹ä»¶å€åŸŸï¼ˆæ”¾å¤§æª¢è¦–ï¼‰",
                        type="filepath",
                        height=400,
                        scale=1
                    )
                
                # æ¨™è¨»é€²åº¦é¡¯ç¤º
                progress_info = gr.Textbox(
                    label="ğŸ“Š æ¨™è¨»é€²åº¦",
                    value="ç­‰å¾…åˆ†æå®Œæˆ...",
                    lines=3,
                    interactive=False
                )
                
                # å¿«é€Ÿæ¨™è¨»æŒ‰éˆ•
                gr.Markdown("### ğŸ·ï¸ å¿«é€Ÿæ¨™è¨»")
                with gr.Row():
                    label_true_btn = gr.Button("âœ… çœŸå¯¦ç«ç…™", variant="primary", scale=2, size="lg")
                    label_false_btn = gr.Button("âŒ èª¤åˆ¤", variant="secondary", scale=2, size="lg")
                
                # å°èˆªæŒ‰éˆ•
                with gr.Row():
                    prev_btn = gr.Button("â¬…ï¸ ä¸Šä¸€å€‹", scale=1)
                    next_btn = gr.Button("â¡ï¸ ä¸‹ä¸€å€‹", scale=1)
                    skip_btn = gr.Button("â­ï¸ è·³é", scale=1)
        
        # æ’­æ”¾æ§åˆ¶å’Œå¹€è³‡è¨Šé¡¯ç¤º
        with gr.Row():
            with gr.Column(scale=3):
                frame_info_display = gr.Textbox(
                    label="ğŸ“¸ å¹€æ’­æ”¾è³‡è¨Š",
                    lines=1,
                    interactive=False,
                    placeholder="ç­‰å¾…äº‹ä»¶è¼‰å…¥..."
                )
            with gr.Column(scale=2):
                playback_speed = gr.Slider(
                    minimum=0.1,
                    maximum=5.0,
                    value=1.0,
                    step=0.1,
                    label="âš¡ æ’­æ”¾é€Ÿåº¦",
                    info="èª¿æ•´å¹€åˆ‡æ›é€Ÿåº¦ï¼ˆå€æ•¸ï¼‰"
                )
        
        # åŒ¯å‡ºè³‡æ–™é›†å€åŸŸ
        with gr.Row():
            with gr.Column():
                gr.Markdown("## ğŸ“¦ åŒ¯å‡ºè³‡æ–™é›†")
                export_btn = gr.Button("ğŸ’¾ åŒ¯å‡ºæ¨™è¨»è³‡æ–™é›†", variant="secondary")
                export_result = gr.Textbox(label="åŒ¯å‡ºçµæœ", lines=3)
                export_file = gr.File(label="ä¸‹è¼‰è³‡æ–™é›†")
        
        # è‡ªå‹•è¼ªæ’­è¨ˆæ™‚å™¨ï¼ˆåˆå§‹å€¼1.0ç§’ï¼Œæœƒæ ¹æ“šæ’­æ”¾é€Ÿåº¦å‹•æ…‹èª¿æ•´ï¼‰
        timer = gr.Timer(value=1.0, active=False)
        
        # é€²åº¦æ›´æ–°è¨ˆæ™‚å™¨  
        progress_timer = gr.Timer(value=1.0, active=False)
        
        # æ’­æ”¾é€Ÿåº¦ç‹€æ…‹
        current_speed = gr.State(1.0)
        
        # æ›´æ–°æ’­æ”¾é€Ÿåº¦
        def update_playback_speed(speed):
            """æ ¹æ“šæ’­æ”¾é€Ÿåº¦èª¿æ•´è¨ˆæ™‚å™¨é–“éš”"""
            # åŸºç¤é–“éš”æ˜¯1.0ç§’ï¼Œé€Ÿåº¦è¶Šå¿«é–“éš”è¶ŠçŸ­
            base_interval = 1.0
            new_interval = base_interval / speed
            # é™åˆ¶é–“éš”ç¯„åœåœ¨0.2ç§’åˆ°10ç§’ä¹‹é–“
            new_interval = max(0.2, min(10.0, new_interval))
            
            # æª¢æŸ¥è¨ˆæ™‚å™¨æ˜¯å¦æ´»èºï¼Œå¦‚æœæ˜¯å‰‡æ›´æ–°é–“éš”ä¸¦ä¿æŒæ´»èºç‹€æ…‹
            is_active = analyzer.current_events and len(analyzer.current_events) > 0
            return gr.Timer(value=new_interval, active=is_active), speed
        
        # æ›´æ–°ç•¶å‰äº‹ä»¶é¡¯ç¤º
        def update_event_display(event_idx, frame_idx):
            try:
                if not analyzer.current_events or event_idx >= len(analyzer.current_events):
                    return "ç„¡äº‹ä»¶", None, None, f"é€²åº¦: 0/0", "ç­‰å¾…äº‹ä»¶è¼‰å…¥...", event_idx, 0
                
                event = analyzer.current_events[event_idx]
                if not event['frames']:
                    return "ç„¡å¹€è³‡æ–™", None, None, f"é€²åº¦: {event_idx+1}/{len(analyzer.current_events)}", "ç„¡å¹€è³‡æ–™", event_idx, 0
                
                # å¾ªç’°é¡¯ç¤ºå¹€
                frame_idx = frame_idx % len(event['frames'])
                frame_info = event['frames'][frame_idx]
                
                # äº‹ä»¶è³‡è¨Š
                info_text = f"äº‹ä»¶ {event_idx+1}/{len(analyzer.current_events)} | " \
                           f"æ™‚é•·: {event['duration']:.1f}ç§’ | " \
                           f"å¹€æ•¸: {event['frame_count']} | " \
                           f"ä¿¡å¿ƒåº¦: {event['avg_confidence']:.2f}"
                
                # é¡¯ç¤ºå½±ç‰‡ä¾†æº
                if 'video_name' in event and event['video_name'] != 'multiple':
                    info_text += f" | ä¾†æº: {event['video_name']}"
                elif 'video_names' in event and len(event['video_names']) > 1:
                    info_text += f" | ä¾†æº: {len(event['video_names'])} å€‹å½±ç‰‡"
                
                if event['label']:
                    info_text += f" | å·²æ¨™è¨»: {event['label']}"
                
                # è©³ç´°é€²åº¦è³‡è¨Š
                labeled_count = sum(1 for e in analyzer.current_events if e['label'] is not None)
                total_count = len(analyzer.current_events)
                video_progress = analyzer._get_video_labeling_progress()
                
                progress_text = f"ç¸½é«”é€²åº¦: {labeled_count}/{total_count} ({labeled_count/total_count*100:.1f}%)\n"
                progress_text += f"ç•¶å‰äº‹ä»¶ä¾†æº: {event.get('video_name', 'unknown')}\n"
                progress_text += video_progress
                
                # å¹€æ’­æ”¾è³‡è¨Š
                frame_info_text = f"ç¬¬ {frame_idx + 1} å¹€ / å…± {len(event['frames'])} å¹€ | " \
                                f"æ™‚é–“: {frame_info['timestamp']:.1f}s | " \
                                f"ä¿¡å¿ƒåº¦: {frame_info['confidence']:.3f}"
                
                # è¿”å›å®Œæ•´ç•«é¢å’Œè£åˆ‡å€åŸŸ
                full_path = frame_info.get('full_path', frame_info['image_path'])
                crop_path = frame_info.get('crop_path', frame_info['image_path'])
                
                return info_text, full_path, crop_path, progress_text, frame_info_text, event_idx, (frame_idx + 1)
            except Exception as e:
                print(f"æ›´æ–°äº‹ä»¶é¡¯ç¤ºæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                return "éŒ¯èª¤", None, None, "éŒ¯èª¤", "éŒ¯èª¤", 0, 0
        
        # æ¨™è¨»ä¸¦ç§»åˆ°ä¸‹ä¸€å€‹
        def label_and_next(event_idx, label):
            if 0 <= event_idx < len(analyzer.current_events):
                # ä½¿ç”¨analyzerçš„label_eventæ–¹æ³•ç²å–è©³ç´°é€²åº¦
                progress_message = analyzer.label_event(event_idx, label)
                
                # æ‰¾ä¸‹ä¸€å€‹æœªæ¨™è¨»çš„äº‹ä»¶
                next_idx = event_idx + 1
                while next_idx < len(analyzer.current_events):
                    if analyzer.current_events[next_idx]['label'] is None:
                        break
                    next_idx += 1
                
                if next_idx >= len(analyzer.current_events):
                    # å¦‚æœæ²’æœ‰æœªæ¨™è¨»çš„ï¼Œå›åˆ°ç¬¬ä¸€å€‹æœªæ¨™è¨»çš„
                    for i in range(len(analyzer.current_events)):
                        if analyzer.current_events[i]['label'] is None:
                            next_idx = i
                            break
                    else:
                        next_idx = 0  # å…¨éƒ¨éƒ½æ¨™è¨»å®Œäº†
                
                return next_idx, 0, progress_message
            return event_idx, 0, "æ¨™è¨»å¤±æ•—"
        
        # å°èˆªå‡½æ•¸
        def go_prev(event_idx):
            new_idx = max(0, event_idx - 1)
            return new_idx, 0
        
        def go_next(event_idx):
            new_idx = min(len(analyzer.current_events) - 1, event_idx + 1) if analyzer.current_events else 0
            return new_idx, 0
        
        def skip_current(event_idx):
            # è·³éç•¶å‰äº‹ä»¶ï¼Œç§»åˆ°ä¸‹ä¸€å€‹
            new_idx = min(len(analyzer.current_events) - 1, event_idx + 1) if analyzer.current_events else 0
            return new_idx, 0
        
        # é€²åº¦æ›´æ–°å‡½æ•¸
        def update_progress():
            """æ›´æ–°åˆ†æé€²åº¦"""
            if hasattr(analyzer, 'current_progress') and analyzer.current_progress:
                progress_text = analyzer.current_progress
            else:
                progress_text = "ç­‰å¾…ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ..."
            
            return progress_text
        
        # æª¢æŸ¥åˆ†æå®Œæˆç‹€æ…‹
        def check_analysis_complete(current_speed_val):
            """æª¢æŸ¥åˆ†ææ˜¯å¦å®Œæˆä¸¦è¿”å›çµæœ"""
            if hasattr(analyzer, 'analysis_complete') and analyzer.analysis_complete:
                if hasattr(analyzer, 'analysis_error') and analyzer.analysis_error:
                    return f"âŒ åˆ†æå¤±æ•—: {analyzer.analysis_error}", [], "", gr.Timer(active=False), 0, 0, gr.Timer(active=False)
                elif hasattr(analyzer, 'analysis_result') and analyzer.analysis_result:
                    result_text, event_gallery, status = analyzer.analysis_result
                    # é‡ç½®å®Œæˆç‹€æ…‹
                    analyzer.analysis_complete = False
                    analyzer.analysis_result = None
                    
                    # å•Ÿå‹•è¼ªæ’­è¨ˆæ™‚å™¨ï¼Œæ ¹æ“šæ’­æ”¾é€Ÿåº¦è¨­å®šé–“éš”
                    if analyzer.current_events:
                        base_interval = 1.0
                        new_interval = base_interval / current_speed_val
                        new_interval = max(0.2, min(10.0, new_interval))
                        return result_text, event_gallery, status, gr.Timer(active=False), 0, 0, gr.Timer(value=new_interval, active=True)
                    else:
                        return result_text, event_gallery, status, gr.Timer(active=False), 0, 0, gr.Timer(active=False)
            
            # å¦‚æœé‚„æ²’å®Œæˆï¼Œä¿æŒé€²åº¦è¨ˆæ™‚å™¨é‹è¡Œ
            return gr.update(), gr.update(), gr.update(), gr.Timer(active=True), gr.update(), gr.update(), gr.update()
        
        # éé˜»å¡çš„åˆ†æè™•ç†
        def start_analysis(files, confidence):
            if not files:
                return "è«‹ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ", gr.Timer(active=False)
            
            # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥
            if analyzer.model is None and ULTRALYTICS_AVAILABLE and Path(analyzer.model_path).exists():
                return "âš ï¸  è«‹å…ˆè¼‰å…¥æ¨¡å‹å†é–‹å§‹åˆ†æ", gr.Timer(active=False)
            
            video_paths = [file.name for file in files] if isinstance(files, list) else [files.name]
            
            # å•Ÿå‹•å¾Œå°åˆ†æä»»å‹™
            def analysis_worker():
                def progress_callback(progress_text):
                    analyzer.current_progress = progress_text
                
                try:
                    result = analyzer.analyze_videos(video_paths, confidence, progress_callback)
                    analyzer.analysis_result = result
                    analyzer.analysis_complete = True
                except Exception as e:
                    analyzer.analysis_error = str(e)
                    analyzer.analysis_complete = True
            
            # é‡ç½®ç‹€æ…‹
            analyzer.analysis_complete = False
            analyzer.analysis_error = None
            analyzer.current_progress = "ğŸš€ æº–å‚™åˆ†æå½±ç‰‡..."
            
            # å•Ÿå‹•èƒŒæ™¯ä»»å‹™
            thread = threading.Thread(target=analysis_worker)
            thread.daemon = True
            thread.start()
            
            return "ğŸš€ é–‹å§‹åˆ†æå½±ç‰‡ï¼Œè«‹æŸ¥çœ‹å³æ™‚é€²åº¦...", gr.Timer(active=True)
        
        # è¼‰å…¥æ¨¡å‹æŒ‰éˆ•é»æ“Š
        load_model_btn.click(
            load_model_to_device,
            inputs=[device_dropdown],
            outputs=[model_status]
        )
        
        # åˆ†æå½±ç‰‡æŒ‰éˆ•é»æ“Š
        analyze_btn.click(
            start_analysis,
            inputs=[video_input, confidence_slider],
            outputs=[analysis_result, progress_timer]
        )
        
        # é€²åº¦è¨ˆæ™‚å™¨æ›´æ–°
        progress_timer.tick(
            update_progress,
            outputs=[progress_display]
        )
        
        # åŒæ™‚æª¢æŸ¥åˆ†æå®Œæˆç‹€æ…‹
        progress_timer.tick(
            check_analysis_complete,
            inputs=[current_speed],
            outputs=[analysis_result, gr.Gallery(visible=False), gr.Textbox(visible=False), progress_timer, current_event_idx, frame_idx, timer]
        )
        
        # è¨ˆæ™‚å™¨è§¸ç™¼æ›´æ–°
        timer.tick(
            update_event_display,
            inputs=[current_event_idx, frame_idx],
            outputs=[current_event_info, full_frame_display, crop_frame_display, progress_info, frame_info_display, current_event_idx, frame_idx]
        )
        
        # æ¨™è¨»äº‹ä»¶
        label_true_btn.click(
            lambda idx: label_and_next(idx, "çœŸå¯¦ç«ç…™"),
            inputs=[current_event_idx],
            outputs=[current_event_idx, frame_idx, analysis_result]
        )
        
        label_false_btn.click(
            lambda idx: label_and_next(idx, "èª¤åˆ¤"),
            inputs=[current_event_idx],
            outputs=[current_event_idx, frame_idx, analysis_result]
        )
        
        # å°èˆªæŒ‰éˆ•
        prev_btn.click(go_prev, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        next_btn.click(go_next, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        skip_btn.click(skip_current, inputs=[current_event_idx], outputs=[current_event_idx, frame_idx])
        
        # æ’­æ”¾é€Ÿåº¦æ§åˆ¶
        playback_speed.change(
            update_playback_speed,
            inputs=[playback_speed],
            outputs=[timer, current_speed]
        )
        
        # åŒ¯å‡ºè³‡æ–™é›†
        def export_and_return_file():
            zip_path, result_text = analyzer.export_dataset()
            return result_text, zip_path
        
        export_btn.click(
            export_and_return_file,
            outputs=[export_result, export_file]
        )
    
    return app

if __name__ == "__main__":
    print("ğŸ”¥ å•Ÿå‹•ç«ç…™èª¤åˆ¤æ¨™è¨»ç³»çµ±...")
    print("=" * 50)
    print("åŠŸèƒ½ï¼š")
    print("âœ… å¤šå½±ç‰‡æ‰¹æ¬¡ä¸Šå‚³å’Œåˆ†æ")
    print("âœ… ä½¿ç”¨ best.pt é€²è¡Œç«ç…™åµæ¸¬")
    print("âœ… ReID æŠ€è¡“è‡ªå‹•åˆ†çµ„äº‹ä»¶")
    print("âœ… çµ±ä¸€æ¨™è¨»æµç¨‹è™•ç†å¤šå½±ç‰‡äº‹ä»¶")
    print("âœ… å¿«é€Ÿæ¨™è¨»çœŸå¯¦/èª¤åˆ¤")
    print("âœ… åŒ¯å‡ºçµæ§‹åŒ–è¨“ç·´è³‡æ–™é›†")
    print("=" * 50)
    
    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )