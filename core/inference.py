#!/usr/bin/env python3
"""
æ¨è«–æ¨¡çµ„
è² è²¬æ¨¡å‹æ¨è«–åŠŸèƒ½
"""

import cv2
import numpy as np
from pathlib import Path
import json
import tempfile
import os
from datetime import datetime

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False


class ModelInference:
    """æ¨¡å‹æ¨è«–å™¨"""
    
    def __init__(self):
        self.inference_dir = Path("inference_workspace")
        self.inference_dir.mkdir(exist_ok=True)
        
        # ç•¶å‰è¼‰å…¥çš„æ¨¡å‹
        self.current_model = None
        self.current_model_path = None
        self.current_model_info = ""
        
        # æ¨è«–çµæœ
        self.inference_results = []
    
    def get_available_models(self):
        """å–å¾—å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        models = []
        
        # é è¨­æ¨¡å‹
        default_model = Path("best.pt")
        if default_model.exists():
            models.append({
                "name": "best.pt (é è¨­æ¨¡å‹)",
                "path": str(default_model),
                "type": "default"
            })
        
        # å·²è¨“ç·´çš„æ¨¡å‹
        runs_dir = Path("runs/detect")
        if runs_dir.exists():
            for run_dir in runs_dir.iterdir():
                if run_dir.is_dir():
                    weights_dir = run_dir / "weights"
                    if weights_dir.exists():
                        best_pt = weights_dir / "best.pt"
                        if best_pt.exists():
                            models.append({
                                "name": f"{run_dir.name}/best.pt",
                                "path": str(best_pt),
                                "type": "trained",
                                "created": best_pt.stat().st_mtime
                            })
        
        # æŒ‰é¡å‹å’Œæ™‚é–“æ’åº
        models.sort(key=lambda x: (x["type"] != "default", -x.get("created", 0)))
        return models
    
    def load_model(self, model_path, device='auto'):
        """è¼‰å…¥æ¨è«–æ¨¡å‹"""
        try:
            if not ULTRALYTICS_AVAILABLE:
                return "âŒ æœªå®‰è£ ultralytics å¥—ä»¶ï¼Œç„¡æ³•è¼‰å…¥æ¨¡å‹"
            
            if not Path(model_path).exists():
                return f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}"
            
            # è¼‰å…¥æ¨¡å‹
            self.current_model = YOLO(model_path)
            
            # è¨­å®šè¨­å‚™
            if device == 'auto':
                # è‡ªå‹•æª¢æ¸¬æœ€ä½³è¨­å‚™
                if hasattr(self.current_model, 'device'):
                    device = str(self.current_model.device)
                else:
                    device = 'cpu'
            
            self.current_model.to(device)
            self.current_model_path = model_path
            
            # å–å¾—æ¨¡å‹è³‡è¨Š
            model_info = self._get_model_info(model_path)
            self.current_model_info = f"""âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼

ğŸ“ æ¨¡å‹è·¯å¾‘: {model_path}
âš¡ é‹ç®—è¨­å‚™: {device}
{model_info}
            """
            
            return self.current_model_info
            
        except Exception as e:
            self.current_model = None
            self.current_model_path = None
            return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    def _get_model_info(self, model_path):
        """å–å¾—æ¨¡å‹è©³ç´°è³‡è¨Š"""
        try:
            # åŸºæœ¬è³‡è¨Š
            file_size = Path(model_path).stat().st_size / (1024 * 1024)  # MB
            info = f"ğŸ“Š æª”æ¡ˆå¤§å°: {file_size:.1f} MB\n"
            
            # å¦‚æœæœ‰æ¨¡å‹çš„è©±ï¼Œå¯ä»¥å–å¾—æ›´å¤šè³‡è¨Š
            if self.current_model:
                # é¡åˆ¥æ•¸é‡
                if hasattr(self.current_model.model, 'nc'):
                    info += f"ğŸ¯ é¡åˆ¥æ•¸é‡: {self.current_model.model.nc}\n"
                
                # é¡åˆ¥åç¨±
                if hasattr(self.current_model.model, 'names'):
                    names = self.current_model.model.names
                    info += f"ğŸ“ é¡åˆ¥åç¨±: {list(names.values())}\n"
            
            return info
            
        except Exception as e:
            return f"âš ï¸ ç„¡æ³•å–å¾—è©³ç´°è³‡è¨Š: {str(e)}\n"
    
    def inference_batch_images(self, image_files, confidence_threshold=0.5):
        """æ‰¹æ¬¡æ¨è«–å¤šå¼µå½±åƒ"""
        try:
            if not self.current_model:
                return "âŒ è«‹å…ˆè¼‰å…¥æ¨¡å‹", []
            
            if not image_files:
                return "âŒ è«‹ä¸Šå‚³å½±åƒæª”æ¡ˆ", []
            
            results = []
            processed_count = 0
            
            # ç¢ºä¿æ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(image_files, list):
                image_files = [image_files]
            
            for img_file in image_files:
                try:
                    # è®€å–å½±åƒ
                    image = cv2.imread(img_file.name)
                    if image is None:
                        results.append({
                            "filename": img_file.name,
                            "error": "ç„¡æ³•è®€å–å½±åƒæª”æ¡ˆ"
                        })
                        continue
                    
                    # é€²è¡Œæ¨è«–
                    prediction_results = self.current_model(image, conf=confidence_threshold, verbose=False)
                    
                    # è™•ç†çµæœ
                    detections = []
                    annotated_image = image.copy()
                    
                    for result in prediction_results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                conf = box.conf[0].cpu().numpy()
                                cls = int(box.cls[0].cpu().numpy())
                                
                                # å–å¾—é¡åˆ¥åç¨±
                                class_name = "unknown"
                                if hasattr(self.current_model.model, 'names'):
                                    class_name = self.current_model.model.names.get(cls, f"class_{cls}")
                                
                                detections.append({
                                    "bbox": [float(x1), float(y1), float(x2), float(y2)],
                                    "confidence": float(conf),
                                    "class": int(cls),
                                    "class_name": class_name
                                })
                                
                                # åœ¨å½±åƒä¸Šç¹ªè£½æ¡†ç·š
                                cv2.rectangle(annotated_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                                cv2.putText(annotated_image, f"{class_name}: {conf:.2f}",
                                          (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                    
                    # å„²å­˜æ¨™è¨»å¾Œçš„å½±åƒ
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_filename = f"inference_result_{processed_count:03d}_{timestamp}.jpg"
                    output_path = self.inference_dir / output_filename
                    cv2.imwrite(str(output_path), annotated_image)
                    
                    results.append({
                        "filename": Path(img_file.name).name,
                        "detections": detections,
                        "detection_count": len(detections),
                        "annotated_image_path": str(output_path),
                        "original_size": image.shape[:2]  # (height, width)
                    })
                    
                    processed_count += 1
                    
                except Exception as e:
                    results.append({
                        "filename": Path(img_file.name).name,
                        "error": str(e)
                    })
            
            # å„²å­˜æ¨è«–çµæœ
            self.inference_results = results
            
            # ç”Ÿæˆæ‘˜è¦
            total_detections = sum(r.get("detection_count", 0) for r in results)
            successful_count = len([r for r in results if "error" not in r])
            error_count = len([r for r in results if "error" in r])
            
            summary = f"""âœ… æ‰¹æ¬¡æ¨è«–å®Œæˆï¼

ğŸ“Š è™•ç†çµæœ:
- æˆåŠŸè™•ç†: {successful_count} å¼µå½±åƒ
- è™•ç†å¤±æ•—: {error_count} å¼µå½±åƒ  
- ç¸½åµæ¸¬æ•¸: {total_detections} å€‹ç‰©ä»¶

ğŸ“ çµæœå„²å­˜åœ¨: {self.inference_dir}
            """
            
            return summary, results
            
        except Exception as e:
            return f"âŒ æ¨è«–å¤±æ•—: {str(e)}", []
    
    def get_inference_results_summary(self):
        """å–å¾—æ¨è«–çµæœæ‘˜è¦"""
        if not self.inference_results:
            return "å°šæœªé€²è¡Œæ¨è«–"
        
        successful_results = [r for r in self.inference_results if "error" not in r]
        error_results = [r for r in self.inference_results if "error" in r]
        
        summary_lines = [
            f"ğŸ“Š æ¨è«–çµæœæ‘˜è¦:",
            f"",
            f"âœ… æˆåŠŸè™•ç†: {len(successful_results)} å¼µå½±åƒ",
            f"âŒ è™•ç†å¤±æ•—: {len(error_results)} å¼µå½±åƒ",
            f""
        ]
        
        if successful_results:
            total_detections = sum(r["detection_count"] for r in successful_results)
            avg_detections = total_detections / len(successful_results)
            summary_lines.extend([
                f"ğŸ¯ ç¸½åµæ¸¬æ•¸: {total_detections} å€‹ç‰©ä»¶",
                f"ğŸ“ˆ å¹³å‡æ¯å¼µ: {avg_detections:.1f} å€‹ç‰©ä»¶",
                f""
            ])
            
            # é¡¯ç¤ºå„å½±åƒçš„çµæœ
            summary_lines.append("ğŸ“‹ è©³ç´°çµæœ:")
            for i, result in enumerate(successful_results[:10]):  # åªé¡¯ç¤ºå‰10å€‹
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                summary_lines.append(f"  {i+1}. {filename}: {result['detection_count']} å€‹ç‰©ä»¶")
            
            if len(successful_results) > 10:
                summary_lines.append(f"  ... é‚„æœ‰ {len(successful_results) - 10} å€‹çµæœ")
        
        if error_results:
            summary_lines.extend([
                f"",
                f"âŒ è™•ç†å¤±æ•—çš„æª”æ¡ˆ:",
            ])
            for result in error_results[:5]:  # åªé¡¯ç¤ºå‰5å€‹éŒ¯èª¤
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                error_msg = result["error"][:50] + "..." if len(result["error"]) > 50 else result["error"]
                summary_lines.append(f"  - {filename}: {error_msg}")
        
        return "\n".join(summary_lines)
    
    def get_detection_gallery(self):
        """å–å¾—åµæ¸¬çµæœå½±åƒç•«å»Š"""
        if not self.inference_results:
            return []
        
        gallery_paths = []
        for result in self.inference_results:
            if "annotated_image_path" in result and Path(result["annotated_image_path"]).exists():
                gallery_paths.append(result["annotated_image_path"])
        
        return gallery_paths
    
    def clear_inference_results(self):
        """æ¸…é™¤æ¨è«–çµæœ"""
        self.inference_results = []
        
        # æ¸…é™¤æš«å­˜æª”æ¡ˆï¼ˆä¿ç•™æœ€è¿‘çš„çµæœï¼‰
        try:
            if self.inference_dir.exists():
                inference_files = list(self.inference_dir.glob("inference_result_*.jpg"))
                # ä¿ç•™æœ€æ–°çš„20å€‹æª”æ¡ˆï¼Œåˆªé™¤å…¶é¤˜çš„
                if len(inference_files) > 20:
                    inference_files.sort(key=lambda x: x.stat().st_mtime)
                    for old_file in inference_files[:-20]:
                        old_file.unlink()
        except Exception as e:
            print(f"æ¸…ç†æ¨è«–çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return "âœ… å·²æ¸…é™¤æ¨è«–çµæœ"