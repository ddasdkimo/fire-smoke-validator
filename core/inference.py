#!/usr/bin/env python3
"""
æ¨è«–æ¨¡çµ„
è² è²¬æ¨¡å‹æ¨è«–åŠŸèƒ½
"""

import cv2
import numpy as np
from pathlib import Path
import json
import tempfile
import os
from datetime import datetime

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False


class ModelInference:
    """æ¨¡å‹æ¨è«–å™¨"""
    
    def __init__(self):
        self.inference_dir = Path("inference_workspace")
        self.inference_dir.mkdir(exist_ok=True)
        
        # ç•¶å‰è¼‰å…¥çš„æ¨¡å‹
        self.current_model = None
        self.current_model_path = None
        self.current_model_info = ""
        
        # æ¨è«–çµæœ
        self.inference_results = []
    
    def get_available_models(self):
        """å–å¾—å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        models = []
        
        # é è¨­æ¨¡å‹
        default_model = Path("best.pt")
        if default_model.exists():
            models.append({
                "name": "best.pt (é è¨­æ¨¡å‹)",
                "path": str(default_model),
                "type": "default"
            })
        
        # å·²è¨“ç·´çš„æ¨¡å‹
        runs_dir = Path("runs/detect")
        if runs_dir.exists():
            for run_dir in runs_dir.iterdir():
                if run_dir.is_dir():
                    weights_dir = run_dir / "weights"
                    if weights_dir.exists():
                        best_pt = weights_dir / "best.pt"
                        if best_pt.exists():
                            models.append({
                                "name": f"{run_dir.name}/best.pt",
                                "path": str(best_pt),
                                "type": "trained",
                                "created": best_pt.stat().st_mtime
                            })
        
        # æŒ‰é¡å‹å’Œæ™‚é–“æ’åº
        models.sort(key=lambda x: (x["type"] != "default", -x.get("created", 0)))
        return models
    
    def load_model(self, model_path, device='auto'):
        """è¼‰å…¥æ¨è«–æ¨¡å‹"""
        try:
            if not Path(model_path).exists():
                return f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}"
            
            # åˆ¤æ–·æ¨¡å‹é¡å‹
            is_temporal_model = self._is_temporal_model(model_path)
            
            if is_temporal_model:
                # è¼‰å…¥æ™‚åºæ¨¡å‹
                return self._load_temporal_model(model_path, device)
            else:
                # è¼‰å…¥ YOLO æ¨¡å‹
                return self._load_yolo_model(model_path, device)
            
        except Exception as e:
            self.current_model = None
            self.current_model_path = None
            return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    def _is_temporal_model(self, model_path):
        """åˆ¤æ–·æ˜¯å¦ç‚ºæ™‚åºæ¨¡å‹"""
        try:
            # å˜—è©¦è¼‰å…¥æª¢æŸ¥é»
            import torch
            checkpoint = torch.load(model_path, map_location='cpu')
            # å¦‚æœæœ‰ model_config ä¸”åŒ…å« backbone_nameï¼Œè¦–ç‚ºæ™‚åºæ¨¡å‹
            return 'model_config' in checkpoint and 'backbone_name' in checkpoint.get('model_config', {})
        except:
            return False
    
    def _load_temporal_model(self, model_path, device):
        """è¼‰å…¥æ™‚åºæ¨¡å‹"""
        try:
            from .models.temporal_trainer import load_temporal_model
            
            # è¨­å®šè¨­å‚™
            if device == 'auto':
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
            
            self.current_model = load_temporal_model(model_path, device)
            self.current_model_path = model_path
            
            # å–å¾—æ¨¡å‹è³‡è¨Š
            model_info = self.current_model.get_model_info()
            self.current_model_info = f"""âœ… æ™‚åºæ¨¡å‹è¼‰å…¥æˆåŠŸï¼

ğŸ“ æ¨¡å‹è·¯å¾‘: {model_path}
âš¡ é‹ç®—è¨­å‚™: {device}
ğŸ¯ æ¨¡å‹é¡å‹: æ™‚åºç«ç…™åˆ†é¡å™¨
ğŸ§  Backbone: {model_info['backbone']}
â±ï¸ æ™‚åºå¹€æ•¸: {model_info['temporal_frames']}
ğŸ”„ èåˆç­–ç•¥: {model_info['temporal_fusion']}
ğŸ“Š åƒæ•¸é‡: {model_info['total_parameters']:,}
ğŸƒ å¯è¨“ç·´åƒæ•¸: {model_info['trainable_parameters']:,}
            """
            
            return self.current_model_info
            
        except ImportError:
            return "âŒ ç¼ºå°‘ timm æˆ–ç›¸é—œä¾è³´ï¼Œç„¡æ³•è¼‰å…¥æ™‚åºæ¨¡å‹"
        except Exception as e:
            return f"âŒ æ™‚åºæ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    def _load_yolo_model(self, model_path, device):
        """è¼‰å…¥ YOLO æ¨¡å‹"""
        try:
            if not ULTRALYTICS_AVAILABLE:
                return "âŒ æœªå®‰è£ ultralytics å¥—ä»¶ï¼Œç„¡æ³•è¼‰å…¥ YOLO æ¨¡å‹"
            
            # è¼‰å…¥æ¨¡å‹
            self.current_model = YOLO(model_path)
            
            # è¨­å®šè¨­å‚™
            if device == 'auto':
                # è‡ªå‹•æª¢æ¸¬æœ€ä½³è¨­å‚™
                if hasattr(self.current_model, 'device'):
                    device = str(self.current_model.device)
                else:
                    device = 'cpu'
            
            self.current_model.to(device)
            self.current_model_path = model_path
            
            # å–å¾—æ¨¡å‹è³‡è¨Š
            model_info = self._get_model_info(model_path)
            self.current_model_info = f"""âœ… YOLO æ¨¡å‹è¼‰å…¥æˆåŠŸï¼

ğŸ“ æ¨¡å‹è·¯å¾‘: {model_path}
âš¡ é‹ç®—è¨­å‚™: {device}
ğŸ¯ æ¨¡å‹é¡å‹: YOLO ç‰©ä»¶åµæ¸¬
{model_info}
            """
            
            return self.current_model_info
            
        except Exception as e:
            return f"âŒ YOLO æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    def _get_model_info(self, model_path):
        """å–å¾—æ¨¡å‹è©³ç´°è³‡è¨Š"""
        try:
            # åŸºæœ¬è³‡è¨Š
            file_size = Path(model_path).stat().st_size / (1024 * 1024)  # MB
            info = f"ğŸ“Š æª”æ¡ˆå¤§å°: {file_size:.1f} MB\n"
            
            # å¦‚æœæœ‰æ¨¡å‹çš„è©±ï¼Œå¯ä»¥å–å¾—æ›´å¤šè³‡è¨Š
            if self.current_model:
                # é¡åˆ¥æ•¸é‡
                if hasattr(self.current_model.model, 'nc'):
                    info += f"ğŸ¯ é¡åˆ¥æ•¸é‡: {self.current_model.model.nc}\n"
                
                # é¡åˆ¥åç¨±
                if hasattr(self.current_model.model, 'names'):
                    names = self.current_model.model.names
                    info += f"ğŸ“ é¡åˆ¥åç¨±: {list(names.values())}\n"
            
            return info
            
        except Exception as e:
            return f"âš ï¸ ç„¡æ³•å–å¾—è©³ç´°è³‡è¨Š: {str(e)}\n"
    
    def inference_batch_images(self, image_files, confidence_threshold=0.5):
        """æ‰¹æ¬¡æ¨è«–å¤šå¼µå½±åƒ"""
        try:
            if not self.current_model:
                return "âŒ è«‹å…ˆè¼‰å…¥æ¨¡å‹", []
            
            if not image_files:
                return "âŒ è«‹ä¸Šå‚³å½±åƒæª”æ¡ˆ", []
            
            # åˆ¤æ–·æ¨¡å‹é¡å‹
            is_temporal_model = self._is_temporal_model(self.current_model_path)
            
            if is_temporal_model:
                return self._inference_temporal_model(image_files, confidence_threshold)
            else:
                return self._inference_yolo_model(image_files, confidence_threshold)
            
        except Exception as e:
            return f"âŒ æ¨è«–å¤±æ•—: {str(e)}", []
    
    def _inference_temporal_model(self, image_files, confidence_threshold=0.5):
        """æ™‚åºæ¨¡å‹æ¨è«–"""
        try:
            from .models.data_utils import prepare_temporal_frames
            import torch
            
            results = []
            processed_count = 0
            
            # ç¢ºä¿æ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(image_files, list):
                image_files = [image_files]
            
            # æ™‚åºæ¨¡å‹éœ€è¦å°‡å¤šå¼µå½±åƒä½œç‚ºä¸€å€‹åºåˆ—è™•ç†
            # é€™è£¡å‡è¨­ç”¨æˆ¶ä¸Šå‚³çš„æ˜¯ä¸€å€‹äº‹ä»¶çš„å¤šå€‹å¹€
            print(f"â±ï¸ æ™‚åºæ¨¡å‹æ¨è«–: è™•ç† {len(image_files)} å¼µå½±åƒä½œç‚ºä¸€å€‹æ™‚åºåºåˆ—...")
            
            try:
                # è¼‰å…¥æ‰€æœ‰å½±åƒä½œç‚ºä¸€å€‹æ™‚åºåºåˆ—
                frames = []
                valid_files = []
                
                for img_file in image_files:
                    image = cv2.imread(img_file.name)
                    if image is not None:
                        frames.append(image)
                        valid_files.append(img_file)
                
                if not frames:
                    return "âŒ ç„¡æ³•è®€å–ä»»ä½•æœ‰æ•ˆå½±åƒ", []
                
                # æº–å‚™æ™‚åºè¼¸å…¥ (T=5)
                temporal_input = prepare_temporal_frames(frames, target_frames=5, training=False)
                temporal_input = temporal_input.unsqueeze(0)  # [1, T, C, H, W] åŠ å…¥ batch ç¶­åº¦
                
                # ç§»å‹•åˆ°æ­£ç¢ºè¨­å‚™
                device = next(self.current_model.parameters()).device
                temporal_input = temporal_input.to(device)
                
                # é€²è¡Œæ¨è«–
                with torch.no_grad():
                    outputs = self.current_model(temporal_input)  # [1, num_classes]
                    probabilities = torch.softmax(outputs, dim=1)  # è½‰æ›ç‚ºæ©Ÿç‡
                    
                    predicted_class = torch.argmax(probabilities, dim=1).item()
                    confidence = probabilities[0][predicted_class].item()
                
                # é¡åˆ¥æ˜ å°„
                class_names = {0: "false_positive", 1: "true_positive"}
                predicted_label = class_names.get(predicted_class, f"class_{predicted_class}")
                
                # å»ºç«‹çµæœåœ–åƒï¼ˆå°‡æ‰€æœ‰å¹€çµ„åˆæˆç¶²æ ¼ï¼‰
                grid_image = self._create_temporal_result_grid(frames, predicted_label, confidence)
                
                # å„²å­˜çµæœåœ–åƒ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"temporal_inference_{timestamp}.jpg"
                output_path = self.inference_dir / output_filename
                cv2.imwrite(str(output_path), grid_image)
                
                sequence_result = {
                    "sequence_id": f"temporal_sequence_{timestamp}",
                    "input_frames": [Path(f.name).name for f in valid_files],
                    "predicted_class": predicted_class,
                    "predicted_label": predicted_label,
                    "confidence": float(confidence),
                    "probabilities": {
                        "false_positive": float(probabilities[0][0]),
                        "true_positive": float(probabilities[0][1])
                    },
                    "result_image_path": str(output_path),
                    "total_frames": len(frames),
                    "processed_frames": 5  # å›ºå®šè™•ç†5å¹€
                }
                
                results.append(sequence_result)
                
                # ç”Ÿæˆæ‘˜è¦
                summary = f"""âœ… æ™‚åºæ¨¡å‹æ¨è«–å®Œæˆï¼

ğŸ¯ æ¨¡å‹é æ¸¬:
- é æ¸¬é¡åˆ¥: {predicted_label}
- ä¿¡å¿ƒåº¦: {confidence:.3f}
- å‡é™½æ€§æ©Ÿç‡: {probabilities[0][0]:.3f}
- çœŸç«ç…™æ©Ÿç‡: {probabilities[0][1]:.3f}

ğŸ“Š è™•ç†çµæœ:
- è¼¸å…¥å¹€æ•¸: {len(frames)} å¼µ
- è™•ç†å¹€æ•¸: 5 å¼µ (T=5 å›ºå®šç­–ç•¥)
- æ™‚åºèåˆ: {self.current_model.temporal_fusion}

ğŸ“ çµæœå„²å­˜åœ¨: {output_path}
                """
                
                self.inference_results = results
                return summary, results
                
            except Exception as e:
                results.append({
                    "sequence_id": "error_sequence",
                    "error": str(e)
                })
                return f"âŒ æ™‚åºæ¨è«–å¤±æ•—: {str(e)}", results
                
        except ImportError:
            return "âŒ ç¼ºå°‘æ™‚åºæ¨¡å‹ç›¸é—œä¾è³´", []
    
    def _inference_yolo_model(self, image_files, confidence_threshold=0.5):
        """YOLO æ¨¡å‹æ¨è«–"""
        results = []
        processed_count = 0
        
        # ç¢ºä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(image_files, list):
            image_files = [image_files]
        
        for img_file in image_files:
            try:
                # è®€å–å½±åƒ
                image = cv2.imread(img_file.name)
                if image is None:
                    results.append({
                        "filename": img_file.name,
                        "error": "ç„¡æ³•è®€å–å½±åƒæª”æ¡ˆ"
                    })
                    continue
                
                # é€²è¡Œæ¨è«–
                prediction_results = self.current_model(image, conf=confidence_threshold, verbose=False)
                
                # è™•ç†çµæœ
                detections = []
                annotated_image = image.copy()
                
                for result in prediction_results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            
                            # å–å¾—é¡åˆ¥åç¨±
                            class_name = "unknown"
                            if hasattr(self.current_model.model, 'names'):
                                class_name = self.current_model.model.names.get(cls, f"class_{cls}")
                            
                            detections.append({
                                "bbox": [float(x1), float(y1), float(x2), float(y2)],
                                "confidence": float(conf),
                                "class": int(cls),
                                "class_name": class_name
                            })
                            
                            # åœ¨å½±åƒä¸Šç¹ªè£½æ¡†ç·š
                            cv2.rectangle(annotated_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                            cv2.putText(annotated_image, f"{class_name}: {conf:.2f}",
                                      (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                
                # å„²å­˜æ¨™è¨»å¾Œçš„å½±åƒ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"yolo_inference_{processed_count:03d}_{timestamp}.jpg"
                output_path = self.inference_dir / output_filename
                cv2.imwrite(str(output_path), annotated_image)
                
                results.append({
                    "filename": Path(img_file.name).name,
                    "detections": detections,
                    "detection_count": len(detections),
                    "annotated_image_path": str(output_path),
                    "original_size": image.shape[:2]  # (height, width)
                })
                
                processed_count += 1
                
            except Exception as e:
                results.append({
                    "filename": Path(img_file.name).name,
                    "error": str(e)
                })
        
        # å„²å­˜æ¨è«–çµæœ
        self.inference_results = results
        
        # ç”Ÿæˆæ‘˜è¦
        total_detections = sum(r.get("detection_count", 0) for r in results)
        successful_count = len([r for r in results if "error" not in r])
        error_count = len([r for r in results if "error" in r])
        
        summary = f"""âœ… YOLO æ‰¹æ¬¡æ¨è«–å®Œæˆï¼

ğŸ“Š è™•ç†çµæœ:
- æˆåŠŸè™•ç†: {successful_count} å¼µå½±åƒ
- è™•ç†å¤±æ•—: {error_count} å¼µå½±åƒ  
- ç¸½åµæ¸¬æ•¸: {total_detections} å€‹ç‰©ä»¶

ğŸ“ çµæœå„²å­˜åœ¨: {self.inference_dir}
        """
        
        return summary, results
    
    def _create_temporal_result_grid(self, frames, predicted_label, confidence):
        """å»ºç«‹æ™‚åºçµæœç¶²æ ¼åœ–åƒ"""
        try:
            # é™åˆ¶é¡¯ç¤ºçš„å¹€æ•¸
            display_frames = frames[:5] if len(frames) > 5 else frames
            
            # èª¿æ•´æ¯å¹€å¤§å°
            target_size = (200, 200)
            resized_frames = []
            for frame in display_frames:
                resized = cv2.resize(frame, target_size)
                resized_frames.append(resized)
            
            # å»ºç«‹ç¶²æ ¼
            rows = 1
            cols = len(resized_frames)
            
            # å»ºç«‹ç©ºç™½ç•«å¸ƒ
            canvas_height = target_size[1] + 100  # é¡å¤–ç©ºé–“ç”¨æ–¼æ–‡å­—
            canvas_width = target_size[0] * cols
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255
            
            # æ”¾ç½®å¹€
            for i, frame in enumerate(resized_frames):
                x_start = i * target_size[0]
                y_start = 50  # ç‚ºé ‚éƒ¨æ–‡å­—ç•™ç©ºé–“
                canvas[y_start:y_start+target_size[1], x_start:x_start+target_size[0]] = frame
                
                # æ·»åŠ å¹€ç·¨è™Ÿ
                cv2.putText(canvas, f"Frame {i+1}", (x_start + 5, y_start - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            # æ·»åŠ é æ¸¬çµæœ
            result_text = f"Prediction: {predicted_label} (Conf: {confidence:.3f})"
            text_color = (0, 255, 0) if predicted_label == "true_positive" else (0, 0, 255)
            cv2.putText(canvas, result_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, text_color, 2)
            
            return canvas
            
        except Exception as e:
            print(f"å»ºç«‹çµæœç¶²æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # å›å‚³ç¬¬ä¸€å¹€ä½œç‚ºå‚™é¸
            return frames[0] if frames else np.zeros((224, 224, 3), dtype=np.uint8)
    
    def get_inference_results_summary(self):
        """å–å¾—æ¨è«–çµæœæ‘˜è¦"""
        if not self.inference_results:
            return "å°šæœªé€²è¡Œæ¨è«–"
        
        successful_results = [r for r in self.inference_results if "error" not in r]
        error_results = [r for r in self.inference_results if "error" in r]
        
        summary_lines = [
            f"ğŸ“Š æ¨è«–çµæœæ‘˜è¦:",
            f"",
            f"âœ… æˆåŠŸè™•ç†: {len(successful_results)} å¼µå½±åƒ",
            f"âŒ è™•ç†å¤±æ•—: {len(error_results)} å¼µå½±åƒ",
            f""
        ]
        
        if successful_results:
            total_detections = sum(r["detection_count"] for r in successful_results)
            avg_detections = total_detections / len(successful_results)
            summary_lines.extend([
                f"ğŸ¯ ç¸½åµæ¸¬æ•¸: {total_detections} å€‹ç‰©ä»¶",
                f"ğŸ“ˆ å¹³å‡æ¯å¼µ: {avg_detections:.1f} å€‹ç‰©ä»¶",
                f""
            ])
            
            # é¡¯ç¤ºå„å½±åƒçš„çµæœ
            summary_lines.append("ğŸ“‹ è©³ç´°çµæœ:")
            for i, result in enumerate(successful_results[:10]):  # åªé¡¯ç¤ºå‰10å€‹
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                summary_lines.append(f"  {i+1}. {filename}: {result['detection_count']} å€‹ç‰©ä»¶")
            
            if len(successful_results) > 10:
                summary_lines.append(f"  ... é‚„æœ‰ {len(successful_results) - 10} å€‹çµæœ")
        
        if error_results:
            summary_lines.extend([
                f"",
                f"âŒ è™•ç†å¤±æ•—çš„æª”æ¡ˆ:",
            ])
            for result in error_results[:5]:  # åªé¡¯ç¤ºå‰5å€‹éŒ¯èª¤
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                error_msg = result["error"][:50] + "..." if len(result["error"]) > 50 else result["error"]
                summary_lines.append(f"  - {filename}: {error_msg}")
        
        return "\n".join(summary_lines)
    
    def get_detection_gallery(self):
        """å–å¾—åµæ¸¬çµæœå½±åƒç•«å»Š"""
        if not self.inference_results:
            return []
        
        gallery_paths = []
        for result in self.inference_results:
            if "annotated_image_path" in result and Path(result["annotated_image_path"]).exists():
                gallery_paths.append(result["annotated_image_path"])
        
        return gallery_paths
    
    def clear_inference_results(self):
        """æ¸…é™¤æ¨è«–çµæœ"""
        self.inference_results = []
        
        # æ¸…é™¤æš«å­˜æª”æ¡ˆï¼ˆä¿ç•™æœ€è¿‘çš„çµæœï¼‰
        try:
            if self.inference_dir.exists():
                inference_files = list(self.inference_dir.glob("inference_result_*.jpg"))
                # ä¿ç•™æœ€æ–°çš„20å€‹æª”æ¡ˆï¼Œåˆªé™¤å…¶é¤˜çš„
                if len(inference_files) > 20:
                    inference_files.sort(key=lambda x: x.stat().st_mtime)
                    for old_file in inference_files[:-20]:
                        old_file.unlink()
        except Exception as e:
            print(f"æ¸…ç†æ¨è«–çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return "âœ… å·²æ¸…é™¤æ¨è«–çµæœ"