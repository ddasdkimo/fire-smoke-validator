#!/usr/bin/env python3
"""
æ¨è«–æ¨¡çµ„
è² è²¬æ¨¡å‹æ¨è«–åŠŸèƒ½
"""

import cv2
import numpy as np
from pathlib import Path
import json
import tempfile
import os
from datetime import datetime

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import matplotlib.pyplot as plt
    import matplotlib.cm as cm
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False




class ModelInference:
    """æ¨¡å‹æ¨è«–å™¨"""
    
    def __init__(self):
        self.inference_dir = Path("inference_workspace")
        self.inference_dir.mkdir(exist_ok=True)
        
        # ç•¶å‰è¼‰å…¥çš„æ¨¡å‹
        self.current_model = None
        self.current_model_path = None
        self.current_model_info = ""
        
        # æ¨è«–çµæœ
        self.inference_results = []
        
    
    def get_available_models(self):
        """å–å¾—å¯ç”¨çš„æ™‚åºæ¨¡å‹åˆ—è¡¨"""
        models = []
        
        # æ™‚åºè¨“ç·´æ¨¡å‹ - å¾ runs/temporal_training ç›®éŒ„
        temporal_runs_dir = Path("runs/temporal_training")
        if temporal_runs_dir.exists():
            for run_dir in temporal_runs_dir.iterdir():
                if run_dir.is_dir():
                    # å°‹æ‰¾ best_model.pth
                    best_model = run_dir / "best_model.pth"
                    tensorboard_dir = run_dir / "tensorboard"
                    training_history = run_dir / "training_history.json"
                    
                    if best_model.exists():
                        model_info = {
                            "name": f"æ™‚åºæ¨¡å‹ - {run_dir.name}",
                            "path": str(best_model),
                            "type": "temporal_best",
                            "created": best_model.stat().st_mtime,
                            "run_dir": str(run_dir)
                        }
                        
                        # æ·»åŠ TensorBoardä¿¡æ¯
                        if tensorboard_dir.exists():
                            model_info["tensorboard_path"] = str(tensorboard_dir)
                            model_info["has_tensorboard"] = True
                        else:
                            model_info["has_tensorboard"] = False
                        
                        # æ·»åŠ è¨“ç·´æ­·å²ä¿¡æ¯
                        if training_history.exists():
                            try:
                                import json
                                with open(training_history, 'r') as f:
                                    history = json.load(f)
                                    model_info["training_metrics"] = {
                                        "best_val_acc": max(history.get("val_acc", [])) if history.get("val_acc") else None,
                                        "final_train_acc": history.get("train_acc", [])[-1] if history.get("train_acc") else None,
                                        "total_epochs": len(history.get("train_acc", []))
                                    }
                            except Exception as e:
                                model_info["training_metrics"] = None
                        
                        models.append(model_info)
                    
                    # å°‹æ‰¾ final_model.pth
                    final_model = run_dir / "final_model.pth"
                    if final_model.exists():
                        model_info = {
                            "name": f"æ™‚åºæ¨¡å‹ (æœ€çµ‚) - {run_dir.name}",
                            "path": str(final_model),
                            "type": "temporal_final",
                            "created": final_model.stat().st_mtime,
                            "run_dir": str(run_dir)
                        }
                        
                        # æ·»åŠ TensorBoardä¿¡æ¯
                        if tensorboard_dir.exists():
                            model_info["tensorboard_path"] = str(tensorboard_dir)
                            model_info["has_tensorboard"] = True
                        else:
                            model_info["has_tensorboard"] = False
                        
                        models.append(model_info)
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œæä¾›é è¨­èªªæ˜
        if not models:
            models.append({
                "name": "å°šç„¡å·²è¨“ç·´æ¨¡å‹ (è«‹å…ˆé€²è¡Œè¨“ç·´)",
                "path": "",
                "type": "placeholder",
                "created": 0
            })
        
        # æŒ‰æ™‚é–“æ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
        models.sort(key=lambda x: -x.get("created", 0))
        return models
    
    def get_model_tensorboard_info(self, model_path):
        """å–å¾—æ¨¡å‹çš„TensorBoardè³‡è¨Š"""
        try:
            model_dir = Path(model_path).parent
            tensorboard_dir = model_dir / "tensorboard"
            training_history_path = model_dir / "training_history.json"
            
            info = {
                "has_tensorboard": tensorboard_dir.exists(),
                "tensorboard_path": str(tensorboard_dir) if tensorboard_dir.exists() else None,
                "tensorboard_command": f"tensorboard --logdir={tensorboard_dir}" if tensorboard_dir.exists() else None,
                "training_metrics": None
            }
            
            # è®€å–è¨“ç·´æ­·å²
            if training_history_path.exists():
                try:
                    with open(training_history_path, 'r') as f:
                        history = json.load(f)
                        
                    metrics = {
                        "total_epochs": len(history.get("train_acc", [])),
                        "best_val_accuracy": max(history.get("val_acc", [])) if history.get("val_acc") else None,
                        "final_train_accuracy": history.get("train_acc", [])[-1] if history.get("train_acc") else None,
                        "final_val_loss": history.get("val_loss", [])[-1] if history.get("val_loss") else None,
                        "final_train_loss": history.get("train_loss", [])[-1] if history.get("train_loss") else None,
                    }
                    
                    info["training_metrics"] = metrics
                    
                except Exception as e:
                    print(f"è®€å–è¨“ç·´æ­·å²å¤±æ•—: {e}")
            
            return info
            
        except Exception as e:
            print(f"å–å¾—TensorBoardè³‡è¨Šå¤±æ•—: {e}")
            return {"has_tensorboard": False, "tensorboard_path": None, "training_metrics": None}
    
    def load_model(self, model_path, device='auto'):
        """è¼‰å…¥æ™‚åºæ¨è«–æ¨¡å‹"""
        try:
            if not model_path or model_path == "":
                return "âŒ è«‹å…ˆé¸æ“‡æœ‰æ•ˆçš„æ¨¡å‹"
            
            if not Path(model_path).exists():
                return f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}"
            
            # è¼‰å…¥æ™‚åºæ¨¡å‹
            return self._load_temporal_model(model_path, device)
            
        except Exception as e:
            self.current_model = None
            self.current_model_path = None
            return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    
    def _load_temporal_model(self, model_path, device):
        """è¼‰å…¥æ™‚åºæ¨¡å‹"""
        try:
            if not TORCH_AVAILABLE:
                return "âŒ PyTorch æœªå®‰è£ï¼Œç„¡æ³•è¼‰å…¥æ™‚åºæ¨¡å‹"
                
            from .models.temporal_trainer import load_temporal_model
            
            # è¨­å®šè¨­å‚™
            if device == 'auto':
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
            
            self.current_model = load_temporal_model(model_path, device)
            self.current_model_path = model_path
            
            
            # å–å¾—æ¨¡å‹è³‡è¨Šå’Œ TensorBoard è³‡è¨Š
            model_info = self.current_model.get_model_info()
            tensorboard_info = self.get_model_tensorboard_info(model_path)
            
            # æ§‹å»ºåŸºæœ¬è³‡è¨Š
            base_info = f"""âœ… æ™‚åºæ¨¡å‹è¼‰å…¥æˆåŠŸï¼

ğŸ“ æ¨¡å‹è·¯å¾‘: {model_path}
âš¡ é‹ç®—è¨­å‚™: {device}
ğŸ¯ æ¨¡å‹é¡å‹: æ™‚åºç«ç…™åˆ†é¡å™¨
ğŸ§  Backbone: {model_info['backbone']}
â±ï¸ æ™‚åºå¹€æ•¸: {model_info['temporal_frames']}
ğŸ”„ èåˆç­–ç•¥: {model_info['temporal_fusion']}
ğŸ“Š åƒæ•¸é‡: {model_info['total_parameters']:,}
ğŸƒ å¯è¨“ç·´åƒæ•¸: {model_info['trainable_parameters']:,}"""

            # æ·»åŠ è¨“ç·´æŒ‡æ¨™è³‡è¨Š
            if tensorboard_info.get("training_metrics"):
                metrics = tensorboard_info["training_metrics"]
                base_info += f"""

ğŸ“ˆ è¨“ç·´æŒ‡æ¨™:
- ç¸½è¨“ç·´è¼ªæ•¸: {metrics.get('total_epochs', 'N/A')}
- æœ€ä½³é©—è­‰æº–ç¢ºç‡: {metrics.get('best_val_accuracy', 'N/A'):.4f}
- æœ€çµ‚è¨“ç·´æº–ç¢ºç‡: {metrics.get('final_train_accuracy', 'N/A'):.4f}
- æœ€çµ‚é©—è­‰æå¤±: {metrics.get('final_val_loss', 'N/A'):.4f}"""

            # æ·»åŠ  TensorBoard è³‡è¨Š
            if tensorboard_info.get("has_tensorboard"):
                base_info += f"""

ğŸ“Š TensorBoard å¯ç”¨:
- è·¯å¾‘: {tensorboard_info['tensorboard_path']}
- å•Ÿå‹•æŒ‡ä»¤: {tensorboard_info['tensorboard_command']}"""
            else:
                base_info += f"""

âš ï¸ æ­¤æ¨¡å‹æ²’æœ‰ TensorBoard è¨˜éŒ„"""

            self.current_model_info = base_info
            
            return self.current_model_info
            
        except ImportError:
            return "âŒ ç¼ºå°‘ timm æˆ–ç›¸é—œä¾è³´ï¼Œç„¡æ³•è¼‰å…¥æ™‚åºæ¨¡å‹"
        except Exception as e:
            return f"âŒ æ™‚åºæ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"
    
    
    def _get_model_info(self, model_path):
        """å–å¾—æ¨¡å‹è©³ç´°è³‡è¨Š"""
        try:
            # åŸºæœ¬è³‡è¨Š
            file_size = Path(model_path).stat().st_size / (1024 * 1024)  # MB
            info = f"ğŸ“Š æª”æ¡ˆå¤§å°: {file_size:.1f} MB\n"
            
            # å¦‚æœæœ‰æ¨¡å‹çš„è©±ï¼Œå¯ä»¥å–å¾—æ›´å¤šè³‡è¨Š
            if self.current_model:
                # é¡åˆ¥æ•¸é‡
                if hasattr(self.current_model.model, 'nc'):
                    info += f"ğŸ¯ é¡åˆ¥æ•¸é‡: {self.current_model.model.nc}\n"
                
                # é¡åˆ¥åç¨±
                if hasattr(self.current_model.model, 'names'):
                    names = self.current_model.model.names
                    info += f"ğŸ“ é¡åˆ¥åç¨±: {list(names.values())}\n"
            
            return info
            
        except Exception as e:
            return f"âš ï¸ ç„¡æ³•å–å¾—è©³ç´°è³‡è¨Š: {str(e)}\n"
    
    def inference_batch_images(self, image_files, confidence_threshold=0.5):
        """æ™‚åºæ¨¡å‹æ‰¹æ¬¡æ¨è«–"""
        try:
            if not self.current_model:
                return "âŒ è«‹å…ˆè¼‰å…¥æ™‚åºæ¨¡å‹", []
            
            if not image_files:
                return "âŒ è«‹ä¸Šå‚³æ™‚åºå½±åƒæª”æ¡ˆï¼ˆå»ºè­°ä¸Šå‚³åŒä¸€äº‹ä»¶çš„å¤šå¹€å½±åƒï¼‰", []
            
            # åŸ·è¡Œæ™‚åºæ¨¡å‹æ¨è«–
            return self._inference_temporal_model(image_files, confidence_threshold)
            
        except Exception as e:
            return f"âŒ æ™‚åºæ¨è«–å¤±æ•—: {str(e)}", []
    
    def _inference_temporal_model(self, image_files, confidence_threshold=0.5):
        """æ™‚åºæ¨¡å‹æ¨è«–"""
        try:
            if not TORCH_AVAILABLE:
                return "âŒ PyTorch æœªå®‰è£ï¼Œç„¡æ³•é€²è¡Œæ™‚åºæ¨è«–", []
                
            from .models.data_utils import prepare_temporal_frames
            
            results = []
            processed_count = 0
            
            # ç¢ºä¿æ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(image_files, list):
                image_files = [image_files]
            
            # æ™‚åºæ¨¡å‹éœ€è¦å°‡å¤šå¼µå½±åƒä½œç‚ºä¸€å€‹åºåˆ—è™•ç†
            # é€™è£¡å‡è¨­ç”¨æˆ¶ä¸Šå‚³çš„æ˜¯ä¸€å€‹äº‹ä»¶çš„å¤šå€‹å¹€
            print(f"â±ï¸ æ™‚åºæ¨¡å‹æ¨è«–: è™•ç† {len(image_files)} å¼µå½±åƒä½œç‚ºä¸€å€‹æ™‚åºåºåˆ—...")
            
            try:
                # è¼‰å…¥æ‰€æœ‰å½±åƒä½œç‚ºä¸€å€‹æ™‚åºåºåˆ—
                frames = []
                valid_files = []
                
                for img_file in image_files:
                    image = cv2.imread(img_file.name)
                    if image is not None:
                        frames.append(image)
                        valid_files.append(img_file)
                
                if not frames:
                    return "âŒ ç„¡æ³•è®€å–ä»»ä½•æœ‰æ•ˆå½±åƒ", []
                
                # æº–å‚™æ™‚åºè¼¸å…¥ (T=5)
                temporal_input = prepare_temporal_frames(frames, target_frames=5, training=False)
                temporal_input = temporal_input.unsqueeze(0)  # [1, T, C, H, W] åŠ å…¥ batch ç¶­åº¦
                
                # ç§»å‹•åˆ°æ­£ç¢ºè¨­å‚™
                device = next(self.current_model.parameters()).device
                temporal_input = temporal_input.to(device)
                
                # é€²è¡Œæ¨è«–
                with torch.no_grad():
                    outputs = self.current_model(temporal_input)  # [1, num_classes]
                    probabilities = torch.softmax(outputs, dim=1)  # è½‰æ›ç‚ºæ©Ÿç‡
                    
                    predicted_class = torch.argmax(probabilities, dim=1).item()
                    confidence = probabilities[0][predicted_class].item()
                
                
                # é¡åˆ¥æ˜ å°„
                class_names = {0: "false_positive", 1: "true_positive"}
                predicted_label = class_names.get(predicted_class, f"class_{predicted_class}")
                
                # å»ºç«‹çµæœåœ–åƒï¼ˆå°‡æ‰€æœ‰å¹€çµ„åˆæˆç¶²æ ¼ï¼‰
                grid_image = self._create_temporal_result_grid(frames, predicted_label, confidence)
                
                # å„²å­˜çµæœåœ–åƒ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"temporal_inference_{timestamp}.jpg"
                output_path = self.inference_dir / output_filename
                cv2.imwrite(str(output_path), grid_image)
                
                
                sequence_result = {
                    "sequence_id": f"temporal_sequence_{timestamp}",
                    "input_frames": [Path(f.name).name for f in valid_files],
                    "predicted_class": predicted_class,
                    "predicted_label": predicted_label,
                    "confidence": float(confidence),
                    "probabilities": {
                        "false_positive": float(probabilities[0][0]),
                        "true_positive": float(probabilities[0][1])
                    },
                    "result_image_path": str(output_path),
                    "total_frames": len(frames),
                    "processed_frames": 5  # å›ºå®šè™•ç†5å¹€
                }
                
                results.append(sequence_result)
                
                # ç”Ÿæˆè©³ç´°æ‘˜è¦
                status_emoji = "ğŸ”¥" if predicted_label == "true_positive" else "âœ…"
                result_name = "çœŸå¯¦ç«ç…™äº‹ä»¶" if predicted_label == "true_positive" else "éç«ç…™äº‹ä»¶"
                
                
                summary = f"""{status_emoji} æ™‚åºæ¨¡å‹æ¨è«–å®Œæˆï¼

ğŸ¯ åˆ†æçµæœ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š é æ¸¬é¡åˆ¥: {result_name}
ğŸ“ˆ ä¿¡å¿ƒåº¦: {confidence:.3f} ({confidence*100:.1f}%)

ğŸ” è©³ç´°æ©Ÿç‡åˆ†ä½ˆ:
- ğŸ”¥ çœŸå¯¦ç«ç…™: {probabilities[0][1]:.3f} ({probabilities[0][1]*100:.1f}%)
- âŒ èª¤å ±äº‹ä»¶: {probabilities[0][0]:.3f} ({probabilities[0][0]*100:.1f}%)

âš™ï¸ è™•ç†åƒæ•¸:
- è¼¸å…¥å¹€æ•¸: {len(frames)} å¼µå½±åƒ
- æ™‚åºé•·åº¦: T=5 (å›ºå®šç­–ç•¥)
- æ¨¡å‹æ¶æ§‹: {self.current_model.backbone_name}
- èåˆæ–¹å¼: {self.current_model.temporal_fusion}

ğŸ’¾ çµæœæª”æ¡ˆ:
- è¦–è¦ºåŒ–çµæœ: {Path(output_path).name}
- å®Œæ•´è·¯å¾‘: {output_path}

ğŸ“… åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                """
                
                self.inference_results = results
                return summary, results
                
            except Exception as e:
                results.append({
                    "sequence_id": "error_sequence",
                    "error": str(e)
                })
                return f"âŒ æ™‚åºæ¨è«–å¤±æ•—: {str(e)}", results
                
        except ImportError:
            return "âŒ ç¼ºå°‘æ™‚åºæ¨¡å‹ç›¸é—œä¾è³´", []
    
    
    
    
    
    
    def _create_temporal_result_grid(self, frames, predicted_label, confidence):
        """å»ºç«‹æ™‚åºçµæœç¶²æ ¼åœ–åƒ"""
        try:
            if not PIL_AVAILABLE:
                # å¦‚æœ PIL ä¸å¯ç”¨ï¼Œä½¿ç”¨è‹±æ–‡ç‰ˆæœ¬
                return self._create_temporal_result_grid_english(frames, predicted_label, confidence)
            
            # é™åˆ¶é¡¯ç¤ºçš„å¹€æ•¸
            display_frames = frames[:5] if len(frames) > 5 else frames
            
            # èª¿æ•´æ¯å¹€å¤§å°
            target_size = (180, 180)
            resized_frames = []
            for frame in display_frames:
                resized = cv2.resize(frame, target_size)
                # å°‡ BGR è½‰æ›ç‚º RGB (PIL ä½¿ç”¨ RGB)
                resized_rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
                resized_frames.append(resized_rgb)
            
            # å»ºç«‹ç¶²æ ¼
            cols = len(resized_frames)
            padding = 10
            
            # å»ºç«‹ç©ºç™½ç•«å¸ƒ
            header_height = 80
            footer_height = 60
            canvas_height = target_size[1] + header_height + footer_height
            canvas_width = target_size[0] * cols + padding * (cols + 1)
            
            # ä½¿ç”¨ PIL å‰µå»ºåœ–åƒ
            canvas = Image.new('RGB', (canvas_width, canvas_height), color=(240, 240, 240))
            draw = ImageDraw.Draw(canvas)
            
            # å˜—è©¦è¼‰å…¥ä¸­æ–‡å­—é«”
            try:
                # å¸¸è¦‹çš„ä¸­æ–‡å­—é«”è·¯å¾‘
                font_paths = [
                    "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
                    "/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf",
                    "/System/Library/Fonts/Arial.ttf",  # macOS
                    "C:\\Windows\\Fonts\\Arial.ttf",    # Windows
                ]
                
                title_font = None
                text_font = None
                small_font = None
                
                for font_path in font_paths:
                    if Path(font_path).exists():
                        title_font = ImageFont.truetype(font_path, 24)
                        text_font = ImageFont.truetype(font_path, 18)
                        small_font = ImageFont.truetype(font_path, 14)
                        break
                
                # å¦‚æœæ‰¾ä¸åˆ°å­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”
                if not title_font:
                    title_font = ImageFont.load_default()
                    text_font = ImageFont.load_default()
                    small_font = ImageFont.load_default()
                    
            except Exception:
                title_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
                small_font = ImageFont.load_default()
            
            # æ·»åŠ æ¨™é¡ŒèƒŒæ™¯
            draw.rectangle([(0, 0), (canvas_width, header_height)], fill=(50, 50, 50))
            
            # æ·»åŠ é æ¸¬çµæœæ¨™é¡Œ
            title_text = "Temporal Fire/Smoke Classification Result"
            draw.text((20, 15), title_text, fill=(255, 255, 255), font=title_font)
            
            # æ·»åŠ é æ¸¬çµæœ
            if predicted_label == "true_positive":
                result_text = "Prediction: Fire/Smoke Detected"
                result_color = (0, 255, 0)  # ç¶ è‰²
                status_text = "Fire/Smoke Event Detected"
            else:
                result_text = "Prediction: No Fire/Smoke"
                result_color = (255, 165, 0)  # æ©™è‰²
                status_text = "Non Fire/Smoke Event"
            
            confidence_text = f"Confidence: {confidence:.3f} ({confidence*100:.1f}%)"
            
            draw.text((20, 45), result_text, fill=result_color, font=text_font)
            draw.text((350, 45), confidence_text, fill=(255, 255, 255), font=text_font)
            
            # æ”¾ç½®å¹€
            for i, frame in enumerate(resized_frames):
                x_start = padding + i * (target_size[0] + padding)
                y_start = header_height + 10
                
                # æ·»åŠ ç™½è‰²é‚Šæ¡†
                border_box = [(x_start-2, y_start-2), (x_start+target_size[0]+2, y_start+target_size[1]+2)]
                draw.rectangle(border_box, outline=(255, 255, 255), width=2)
                
                # å°‡ numpy é™£åˆ—è½‰æ›ç‚º PIL åœ–åƒ
                frame_img = Image.fromarray(frame)
                canvas.paste(frame_img, (x_start, y_start))
                
                # æ·»åŠ å¹€ç·¨è™Ÿ
                frame_text = f"Frame {i+1}"
                draw.text((x_start + 5, y_start - 20), frame_text, fill=(100, 100, 100), font=small_font)
            
            # æ·»åŠ åº•éƒ¨ç‹€æ…‹
            footer_y = header_height + target_size[1] + 20
            footer_box = [(0, footer_y), (canvas_width, canvas_height)]
            draw.rectangle(footer_box, fill=(240, 240, 240))
            
            draw.text((20, footer_y + 15), status_text, fill=result_color, font=text_font)
            
            # æ·»åŠ è™•ç†ä¿¡æ¯
            info_text = f"Processed {len(display_frames)} frames, Temporal Length: T=5"
            draw.text((20, footer_y + 35), info_text, fill=(100, 100, 100), font=small_font)
            
            # å°‡ PIL åœ–åƒè½‰æ›å› OpenCV æ ¼å¼ (RGB -> BGR)
            canvas_array = np.array(canvas)
            canvas_bgr = cv2.cvtColor(canvas_array, cv2.COLOR_RGB2BGR)
            
            return canvas_bgr
            
        except Exception as e:
            print(f"å»ºç«‹çµæœç¶²æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # å›å‚³è‹±æ–‡ç‰ˆæœ¬ä½œç‚ºå‚™é¸
            return self._create_temporal_result_grid_english(frames, predicted_label, confidence)
    
    def _create_temporal_result_grid_english(self, frames, predicted_label, confidence):
        """å»ºç«‹æ™‚åºçµæœç¶²æ ¼åœ–åƒ (è‹±æ–‡ç‰ˆæœ¬)"""
        try:
            # é™åˆ¶é¡¯ç¤ºçš„å¹€æ•¸
            display_frames = frames[:5] if len(frames) > 5 else frames
            
            # èª¿æ•´æ¯å¹€å¤§å°
            target_size = (180, 180)
            resized_frames = []
            for frame in display_frames:
                resized = cv2.resize(frame, target_size)
                resized_frames.append(resized)
            
            # å»ºç«‹ç¶²æ ¼
            cols = len(resized_frames)
            padding = 10
            
            # å»ºç«‹ç©ºç™½ç•«å¸ƒ
            header_height = 80
            footer_height = 60
            canvas_height = target_size[1] + header_height + footer_height
            canvas_width = target_size[0] * cols + padding * (cols + 1)
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 240
            
            # æ·»åŠ æ¨™é¡ŒèƒŒæ™¯
            cv2.rectangle(canvas, (0, 0), (canvas_width, header_height), (50, 50, 50), -1)
            
            # æ·»åŠ é æ¸¬çµæœæ¨™é¡Œ
            title_text = "Temporal Fire/Smoke Classification"
            cv2.putText(canvas, title_text, (20, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # æ·»åŠ é æ¸¬çµæœ
            if predicted_label == "true_positive":
                result_text = "Fire/Smoke Detected"
                result_color = (0, 255, 0)  # ç¶ è‰²
                status_text = "Fire/Smoke Event"
            else:
                result_text = "No Fire/Smoke"
                result_color = (0, 165, 255)  # æ©™è‰²
                status_text = "Non Fire/Smoke Event"
            
            confidence_text = f"Confidence: {confidence:.3f}"
            
            cv2.putText(canvas, result_text, (20, 55),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, result_color, 2)
            cv2.putText(canvas, confidence_text, (300, 55),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # æ”¾ç½®å¹€
            for i, frame in enumerate(resized_frames):
                x_start = padding + i * (target_size[0] + padding)
                y_start = header_height + 10
                
                # æ·»åŠ ç™½è‰²é‚Šæ¡†
                cv2.rectangle(canvas, (x_start-2, y_start-2), 
                             (x_start+target_size[0]+2, y_start+target_size[1]+2), 
                             (255, 255, 255), 2)
                
                canvas[y_start:y_start+target_size[1], x_start:x_start+target_size[0]] = frame
                
                # æ·»åŠ å¹€ç·¨è™Ÿ
                cv2.putText(canvas, f"Frame {i+1}", (x_start + 5, y_start - 8),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
            
            # æ·»åŠ åº•éƒ¨ç‹€æ…‹
            footer_y = header_height + target_size[1] + 20
            cv2.rectangle(canvas, (0, footer_y), (canvas_width, canvas_height), (240, 240, 240), -1)
            cv2.putText(canvas, status_text, (20, footer_y + 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, result_color, 2)
            
            # æ·»åŠ è™•ç†ä¿¡æ¯
            info_text = f"Processed {len(display_frames)} frames, T=5"
            cv2.putText(canvas, info_text, (20, footer_y + 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
            
            return canvas
            
        except Exception as e:
            print(f"å»ºç«‹çµæœç¶²æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # å›å‚³ç¬¬ä¸€å¹€ä½œç‚ºå‚™é¸
            return frames[0] if frames else np.zeros((224, 224, 3), dtype=np.uint8)
    
    def get_inference_results_summary(self):
        """å–å¾—æ¨è«–çµæœæ‘˜è¦"""
        if not self.inference_results:
            return "å°šæœªé€²è¡Œæ¨è«–"
        
        successful_results = [r for r in self.inference_results if "error" not in r]
        error_results = [r for r in self.inference_results if "error" in r]
        
        summary_lines = [
            f"ğŸ“Š æ¨è«–çµæœæ‘˜è¦:",
            f"",
            f"âœ… æˆåŠŸè™•ç†: {len(successful_results)} å¼µå½±åƒ",
            f"âŒ è™•ç†å¤±æ•—: {len(error_results)} å¼µå½±åƒ",
            f""
        ]
        
        if successful_results:
            total_detections = sum(r["detection_count"] for r in successful_results)
            avg_detections = total_detections / len(successful_results)
            summary_lines.extend([
                f"ğŸ¯ ç¸½åµæ¸¬æ•¸: {total_detections} å€‹ç‰©ä»¶",
                f"ğŸ“ˆ å¹³å‡æ¯å¼µ: {avg_detections:.1f} å€‹ç‰©ä»¶",
                f""
            ])
            
            # é¡¯ç¤ºå„å½±åƒçš„çµæœ
            summary_lines.append("ğŸ“‹ è©³ç´°çµæœ:")
            for i, result in enumerate(successful_results[:10]):  # åªé¡¯ç¤ºå‰10å€‹
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                summary_lines.append(f"  {i+1}. {filename}: {result['detection_count']} å€‹ç‰©ä»¶")
            
            if len(successful_results) > 10:
                summary_lines.append(f"  ... é‚„æœ‰ {len(successful_results) - 10} å€‹çµæœ")
        
        if error_results:
            summary_lines.extend([
                f"",
                f"âŒ è™•ç†å¤±æ•—çš„æª”æ¡ˆ:",
            ])
            for result in error_results[:5]:  # åªé¡¯ç¤ºå‰5å€‹éŒ¯èª¤
                filename = result["filename"][:30] + "..." if len(result["filename"]) > 30 else result["filename"]
                error_msg = result["error"][:50] + "..." if len(result["error"]) > 50 else result["error"]
                summary_lines.append(f"  - {filename}: {error_msg}")
        
        return "\n".join(summary_lines)
    
    def get_detection_gallery(self):
        """å–å¾—åµæ¸¬çµæœå½±åƒç•«å»Š"""
        if not self.inference_results:
            return []
        
        gallery_paths = []
        for result in self.inference_results:
            # æª¢æŸ¥æ™‚åºæ¨¡å‹çµæœ
            if "result_image_path" in result and Path(result["result_image_path"]).exists():
                gallery_paths.append(result["result_image_path"])
            # æª¢æŸ¥å…¶ä»–æ¨¡å‹çµæœ
            elif "annotated_image_path" in result and Path(result["annotated_image_path"]).exists():
                gallery_paths.append(result["annotated_image_path"])
        
        return gallery_paths
    
    
    def clear_inference_results(self):
        """æ¸…é™¤æ¨è«–çµæœ"""
        self.inference_results = []
        
        # æ¸…é™¤æš«å­˜æª”æ¡ˆï¼ˆä¿ç•™æœ€è¿‘çš„çµæœï¼‰
        try:
            if self.inference_dir.exists():
                inference_files = list(self.inference_dir.glob("inference_result_*.jpg"))
                # ä¿ç•™æœ€æ–°çš„20å€‹æª”æ¡ˆï¼Œåˆªé™¤å…¶é¤˜çš„
                if len(inference_files) > 20:
                    inference_files.sort(key=lambda x: x.stat().st_mtime)
                    for old_file in inference_files[:-20]:
                        old_file.unlink()
        except Exception as e:
            print(f"æ¸…ç†æ¨è«–çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return "âœ… å·²æ¸…é™¤æ¨è«–çµæœ"