#!/usr/bin/env python3
"""
è¦–é »åˆ†æå™¨æ ¸å¿ƒæ¨¡çµ„
è² è²¬å½±ç‰‡è™•ç†ã€ç‰©ä»¶åµæ¸¬ã€äº‹ä»¶åˆ†çµ„ç­‰æ ¸å¿ƒåŠŸèƒ½
"""

import cv2
import numpy as np
from pathlib import Path
import json
import uuid
from datetime import datetime
import tempfile
import os
from collections import defaultdict
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False

try:
    import supervision as sv
    SUPERVISION_AVAILABLE = True
except ImportError:
    SUPERVISION_AVAILABLE = False

try:
    import psutil
    import gc
    MEMORY_MONITORING_AVAILABLE = True
except ImportError:
    MEMORY_MONITORING_AVAILABLE = False


class VideoAnalyzer:
    """è¦–é »åˆ†æå™¨ä¸»é¡"""
    
    def __init__(self):
        self.model_path = "best.pt"
        self.work_dir = Path("temp_analysis")
        self.work_dir.mkdir(exist_ok=True)
        self.dataset_dir = Path("dataset")
        self.dataset_dir.mkdir(exist_ok=True)
        
        # é€²åº¦è¿½è¹¤
        self.progress_queue = queue.Queue()
        self.analysis_status = {}
        self.max_workers = min(4, os.cpu_count() or 1)
        
        # æª¢æ¸¬å¯ç”¨è¨­å‚™
        self.available_devices = self._detect_available_devices()
        self.current_device = self.available_devices['default']
        
        # å»¶é²æ¨¡å‹è¼‰å…¥
        self.model = None
        
        # åˆå§‹åŒ–è¿½è¹¤å™¨
        if SUPERVISION_AVAILABLE:
            self.tracker = sv.ByteTrack()
        else:
            self.tracker = None
        
        self.current_events = []
        self.session_id = None
        
        # è¨˜æ†¶é«”ç®¡ç†
        self._cleanup_old_sessions()
    
    def _detect_available_devices(self):
        """æª¢æ¸¬å¯ç”¨çš„è¨ˆç®—è¨­å‚™"""
        devices = {
            'options': ['cpu'],
            'default': 'cpu',
            'status': {'cpu': 'âœ… å¯ç”¨'}
        }
        
        if ULTRALYTICS_AVAILABLE:
            try:
                import torch
                
                # æª¢æŸ¥ CUDA
                if torch.cuda.is_available():
                    devices['options'].insert(0, 'cuda')
                    devices['default'] = 'cuda'
                    device_name = torch.cuda.get_device_name()
                    devices['status']['cuda'] = f'âœ… å¯ç”¨ ({device_name})'
                    print(f"âœ… æª¢æ¸¬åˆ° CUDA: {device_name}")
                else:
                    devices['status']['cuda'] = 'âŒ ä¸å¯ç”¨'
                
                # æª¢æŸ¥ MPS (Apple Silicon)
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    if 'cuda' not in devices['options']:
                        devices['options'].insert(0, 'mps')
                        devices['default'] = 'mps'
                    else:
                        devices['options'].insert(1, 'mps')
                    devices['status']['mps'] = 'âœ… å¯ç”¨ (Apple Silicon)'
                    print("âœ… æª¢æ¸¬åˆ° MPS (Apple Silicon)")
                else:
                    devices['status']['mps'] = 'âŒ ä¸å¯ç”¨'
                    
            except Exception as e:
                print(f"è¨­å‚™æª¢æ¸¬éŒ¯èª¤: {e}")
        
        return devices
    
    def load_model(self, device='auto'):
        """è¼‰å…¥æˆ–é‡æ–°è¼‰å…¥æ¨¡å‹åˆ°æŒ‡å®šè¨­å‚™"""
        if device == 'auto':
            device = self.current_device
        
        try:
            if ULTRALYTICS_AVAILABLE and Path(self.model_path).exists():
                print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹åˆ° {device}...")
                
                # é‡‹æ”¾èˆŠæ¨¡å‹
                if self.model is not None:
                    del self.model
                    if MEMORY_MONITORING_AVAILABLE:
                        gc.collect()
                
                self.model = YOLO(self.model_path)
                self.model.to(device)
                self.current_device = device
                print(f"âœ… å·²è¼‰å…¥ best.pt æ¨¡å‹åˆ° {device}")
                return f"âœ… æ¨¡å‹å·²è¼‰å…¥åˆ° {device}"
            else:
                self.model = None
                print("âš ï¸  æœªæ‰¾åˆ° best.ptï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬åµæ¸¬")
                return "âš ï¸  æœªæ‰¾åˆ° best.ptï¼Œä½¿ç”¨æ¨¡æ“¬åµæ¸¬"
        except Exception as e:
            print(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            if device != 'cpu':
                print("å˜—è©¦å›é€€åˆ° CPU...")
                return self.load_model('cpu')
            else:
                self.model = None
                return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}"
        
        # è¨˜æ†¶é«”ç®¡ç†
        self._cleanup_old_sessions()
    
    def analyze_videos(self, video_paths, confidence_threshold=0.300, min_frames=2, max_frames=30, progress_callback=None):
        """åˆ†æå¤šå€‹å½±ç‰‡ï¼Œæå–äº‹ä»¶ï¼ˆæ”¯æ´ä¸¦ç™¼è™•ç†ï¼‰"""
        try:
            if not video_paths:
                return "è«‹ä¸Šå‚³å½±ç‰‡æª”æ¡ˆ", [], ""
            
            # ç¢ºä¿æ˜¯ä¸²åˆ—
            if not isinstance(video_paths, list):
                video_paths = [video_paths]
            
            self.session_id = str(uuid.uuid4())[:8]
            session_dir = self.work_dir / self.session_id
            session_dir.mkdir(exist_ok=True)
            
            # åˆå§‹åŒ–é€²åº¦è¿½è¹¤
            self.analysis_status = {}
            for i, path in enumerate(video_paths):
                video_name = Path(path).name
                self.analysis_status[i] = {
                    'name': video_name,
                    'status': 'ç­‰å¾…ä¸­',
                    'progress': 0,
                    'detections': 0
                }
            
            all_video_detections = []
            video_summaries = []
            
            print(f"æº–å‚™ä¸¦ç™¼åˆ†æ {len(video_paths)} å€‹å½±ç‰‡ï¼ˆæœ€å¤š {self.max_workers} å€‹ä¸¦ç™¼ï¼‰...")
            
            if progress_callback:
                progress_callback(self._format_progress_text())
            
            # ä½¿ç”¨ç·šç¨‹æ± ä¸¦ç™¼è™•ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»å‹™
                future_to_video = {
                    executor.submit(self._analyze_single_video_with_progress, video_path, video_idx, Path(video_path).name, confidence_threshold, progress_callback): (video_idx, video_path)
                    for video_idx, video_path in enumerate(video_paths)
                }
                
                # æ”¶é›†çµæœ
                for future in as_completed(future_to_video):
                    video_idx, video_path = future_to_video[future]
                    try:
                        video_detections, summary = future.result()
                        video_summaries.append(summary)
                        all_video_detections.extend(video_detections)
                        
                        # æ›´æ–°ç‹€æ…‹
                        self.analysis_status[video_idx]['status'] = 'å®Œæˆ'
                        if progress_callback:
                            progress_callback(self._format_progress_text())
                            
                    except Exception as e:
                        print(f"åˆ†æå½±ç‰‡ {Path(video_path).name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                        self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
                        self.analysis_status[video_idx]['error'] = str(e)
                        if progress_callback:
                            progress_callback(self._format_progress_text())
            
            print(f"\nç¸½å…±åµæ¸¬åˆ° {len(all_video_detections)} å€‹ç‰©ä»¶ï¼Œé–‹å§‹åˆ†çµ„...")
            if progress_callback:
                progress_callback(self._format_progress_text() + "\n\nğŸ”„ æ­£åœ¨åˆ†çµ„äº‹ä»¶...")
            
            # æŒ‰ ReID åˆ†çµ„äº‹ä»¶
            events = self._group_detections_by_reid(all_video_detections, session_dir, min_frames, max_frames)
            
            print(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶")
            
            self.current_events = events
            
            # ç”Ÿæˆåˆ†æçµæœ
            result_text = f"""
åˆ†æå®Œæˆï¼
å½±ç‰‡æ•¸é‡ï¼š{len(video_paths)} å€‹
"""
            for summary in video_summaries:
                result_text += f"\n{summary['name']}: {summary['detections']} å€‹åµæ¸¬, {summary['duration']:.1f} ç§’"
            
            result_text += f"""

ç¸½åµæ¸¬æ•¸ï¼š{len(all_video_detections)} å€‹
åˆ†çµ„äº‹ä»¶æ•¸ï¼š{len(events)} å€‹

ä½¿ç”¨ä¸Šæ–¹è¼ªæ’­ä»‹é¢é€²è¡Œæ¨™è¨»
            """.strip()
            
            # ç”Ÿæˆäº‹ä»¶ç¸®åœ–ä¾›é¸æ“‡
            event_gallery = []
            for i, event in enumerate(events):
                if event['frames']:
                    first_frame_path = event['frames'][0]['image_path']
                    event_gallery.append(first_frame_path)
            
            return result_text, event_gallery, f"æ‰¾åˆ° {len(events)} å€‹äº‹ä»¶"
            
        except Exception as e:
            print(f"åˆ†æå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"åˆ†æå¤±æ•—: {str(e)}", [], "éŒ¯èª¤"
    
    def _analyze_single_video_with_progress(self, video_path, video_idx, video_name, confidence_threshold, progress_callback):
        """å¸¶é€²åº¦å›é¥‹çš„å–®å€‹å½±ç‰‡åˆ†æ"""
        try:
            # æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
            self.analysis_status[video_idx]['status'] = 'è™•ç†ä¸­'
            if progress_callback:
                progress_callback(self._format_progress_text())
            
            # æ‰“é–‹å½±ç‰‡
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
                self.analysis_status[video_idx]['error'] = 'ç„¡æ³•æ‰“é–‹å½±ç‰‡'
                return [], {'name': video_name, 'detections': 0, 'duration': 0}
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # æ”¶é›†åµæ¸¬çµæœ
            video_detections = []
            frame_idx = 0
            sample_interval = max(1, int(fps * 1.0))
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ›´æ–°é€²åº¦
                progress_percent = int((frame_idx / total_frames) * 100) if total_frames > 0 else 0
                self.analysis_status[video_idx]['progress'] = progress_percent
                
                # æ¯100å¹€æˆ–é€²åº¦è®ŠåŒ–æ™‚æ›´æ–°ä»‹é¢
                if frame_idx % 100 == 0 or progress_percent != self.analysis_status[video_idx].get('last_progress', -1):
                    self.analysis_status[video_idx]['last_progress'] = progress_percent
                    if progress_callback:
                        progress_callback(self._format_progress_text())
                
                # æ¡æ¨£ç­–ç•¥ï¼šæ¯ç§’å–ä¸€å¹€
                if frame_idx % sample_interval == 0:
                    timestamp = frame_idx / fps
                    detections = self._detect_objects(frame, frame_idx, timestamp, confidence_threshold)
                    if detections:
                        # åŠ ä¸Šå½±ç‰‡ä¾†æºè³‡è¨Š
                        for det in detections:
                            det['video_name'] = video_name
                            det['video_idx'] = video_idx
                        video_detections.extend(detections)
                        
                        # æ›´æ–°åµæ¸¬æ•¸é‡
                        self.analysis_status[video_idx]['detections'] = len(video_detections)
                
                frame_idx += 1
                
                # é‡‹æ”¾è¨˜æ†¶é«”å’Œå„ªåŒ–
                if frame_idx % 500 == 0:
                    memory_usage = self._optimize_memory_usage()
                    if frame_idx % 1000 == 0:
                        print(f"è¨˜æ†¶é«”ä½¿ç”¨: {memory_usage:.1f} MB")
            
            cap.release()
            
            # å®Œæˆç‹€æ…‹
            self.analysis_status[video_idx]['progress'] = 100
            self.analysis_status[video_idx]['detections'] = len(video_detections)
            
            summary = {
                'name': video_name,
                'detections': len(video_detections),
                'duration': duration
            }
            
            return video_detections, summary
            
        except Exception as e:
            self.analysis_status[video_idx]['status'] = 'éŒ¯èª¤'
            self.analysis_status[video_idx]['error'] = str(e)
            if progress_callback:
                progress_callback(self._format_progress_text())
            raise e
    
    def _detect_objects(self, frame, frame_idx, timestamp, confidence_threshold=0.300):
        """åœ¨å¹€ä¸­åµæ¸¬ç‰©ä»¶"""
        try:
            if self.model:
                # ä½¿ç”¨çœŸå¯¦çš„ YOLO æ¨¡å‹
                results = self.model(frame, conf=confidence_threshold, verbose=False)
                detections = []
                
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())
                            
                            # è£åˆ‡æª¢æ¸¬å€åŸŸ
                            crop = frame[int(y1):int(y2), int(x1):int(x2)]
                            if crop.size > 0:
                                detections.append({
                                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                    'confidence': float(conf),
                                    'class': int(cls),
                                    'frame_idx': frame_idx,
                                    'timestamp': timestamp,
                                    'crop': crop,
                                    'full_frame': frame.copy()
                                })
                return detections
            else:
                # æ¨¡æ“¬åµæ¸¬ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
                h, w = frame.shape[:2]
                if frame_idx % 10 == 0:
                    x1, y1 = w//4, h//4
                    x2, y2 = w*3//4, h*3//4
                    crop = frame[y1:y2, x1:x2]
                    return [{
                        'bbox': [x1, y1, x2, y2],
                        'confidence': 0.8,
                        'class': 0,
                        'frame_idx': frame_idx,
                        'timestamp': timestamp,
                        'crop': crop,
                        'full_frame': frame.copy()
                    }]
                return []
        except Exception as e:
            print(f"åµæ¸¬ç‰©ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def _group_detections_by_reid(self, detections, session_dir, min_frames=2, max_frames=30):
        """ä½¿ç”¨ ReID åˆ†çµ„åµæ¸¬çµæœï¼Œé•·äº‹ä»¶æœƒè‡ªå‹•åˆ†å‰²æˆå¤šå€‹å­äº‹ä»¶"""
        try:
            if not detections:
                return []
            
            # ç¬¬ä¸€éšæ®µï¼šæŒ‰ä½ç½®å’Œæ™‚é–“åˆ†çµ„ï¼ˆä¸é™åˆ¶å¹€æ•¸ï¼‰
            initial_groups = defaultdict(list)
            
            # æŒ‰æ™‚é–“æ’åºåµæ¸¬çµæœ
            sorted_detections = sorted(detections, key=lambda d: d['timestamp'])
            
            for det in sorted_detections:
                # è¨ˆç®—ä¸­å¿ƒé»
                x1, y1, x2, y2 = det['bbox']
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                # æ‰¾åˆ°æœ€è¿‘çš„çµ„åˆ¥
                best_group = None
                min_distance = float('inf')
                
                for group_id, group_dets in initial_groups.items():
                    # è¨ˆç®—èˆ‡çµ„åˆ¥ä¸­æœ€å¾Œä¸€å€‹åµæ¸¬çš„è·é›¢
                    last_det = group_dets[-1]
                    last_x1, last_y1, last_x2, last_y2 = last_det['bbox']
                    last_center_x = (last_x1 + last_x2) / 2
                    last_center_y = (last_y1 + last_y2) / 2
                    
                    distance = np.sqrt((center_x - last_center_x)**2 + (center_y - last_center_y)**2)
                    time_diff = abs(det['timestamp'] - last_det['timestamp'])
                    
                    # å¦‚æœä½ç½®æ¥è¿‘ä¸”æ™‚é–“å·®ä¸å¤§ï¼Œè¦–ç‚ºåŒä¸€ ReID è¿½è¹¤
                    if distance < 100 and time_diff < 10:
                        if distance < min_distance:
                            min_distance = distance
                            best_group = group_id
                
                if best_group is not None:
                    initial_groups[best_group].append(det)
                else:
                    # å‰µå»ºæ–°çµ„åˆ¥
                    new_group_id = len(initial_groups)
                    initial_groups[new_group_id].append(det)
            
            # ç¬¬äºŒéšæ®µï¼šå°‡é•·äº‹ä»¶åˆ†å‰²æˆç¬¦åˆå¹€æ•¸é™åˆ¶çš„å­äº‹ä»¶
            events = []
            event_counter = 0
            
            for group_id, group_dets in initial_groups.items():
                print(f"è™•ç†åŸå§‹çµ„åˆ¥ {group_id}ï¼šå…± {len(group_dets)} å¹€")
                
                # å¦‚æœçµ„åˆ¥å°‘æ–¼æœ€å°‘å¹€æ•¸ï¼Œç›´æ¥å¿½ç•¥
                if len(group_dets) < min_frames:
                    print(f"  å¿½ç•¥ï¼šåªæœ‰ {len(group_dets)} å¹€ï¼Œå°‘æ–¼æœ€å°‘è¦æ±‚ {min_frames} å¹€")
                    continue
                
                # å°‡é•·äº‹ä»¶åˆ†å‰²æˆå¤šå€‹å­äº‹ä»¶
                num_chunks = (len(group_dets) + max_frames - 1) // max_frames  # å‘ä¸Šå–æ•´
                
                for chunk_idx in range(num_chunks):
                    start_idx = chunk_idx * max_frames
                    end_idx = min(start_idx + max_frames, len(group_dets))
                    chunk_dets = group_dets[start_idx:end_idx]
                    
                    # æª¢æŸ¥å­äº‹ä»¶æ˜¯å¦æ»¿è¶³æœ€å°‘å¹€æ•¸è¦æ±‚
                    if len(chunk_dets) >= min_frames:
                        event_dir = session_dir / f"event_{event_counter}"
                        event_dir.mkdir(exist_ok=True)
                        self._process_event_chunk(chunk_dets, event_dir, event_counter, events)
                        print(f"  å‰µå»ºå­äº‹ä»¶ {event_counter}ï¼š{len(chunk_dets)} å¹€ (ç¬¬ {chunk_idx+1}/{num_chunks} æ®µ)")
                        event_counter += 1
                    else:
                        print(f"  è·³éå­äº‹ä»¶ï¼šåªæœ‰ {len(chunk_dets)} å¹€ï¼Œå°‘æ–¼æœ€å°‘è¦æ±‚ {min_frames} å¹€")
            
            # çµ±è¨ˆä¿¡æ¯
            total_detections = len(detections)
            total_groups = len(initial_groups)
            total_events = len(events)
            
            print(f"åˆ†çµ„å®Œæˆï¼š")
            print(f"  - ç¸½åµæ¸¬æ•¸: {total_detections}")
            print(f"  - åˆå§‹ ReID çµ„: {total_groups}")
            print(f"  - æœ€çµ‚äº‹ä»¶æ•¸: {total_events}")
            
            # æª¢æŸ¥äº‹ä»¶å¹€æ•¸åˆ†å¸ƒ
            frame_counts = [len(event['frames']) for event in events]
            if frame_counts:
                print(f"  - äº‹ä»¶å¹€æ•¸ç¯„åœ: {min(frame_counts)} - {max(frame_counts)} å¹€")
                print(f"  - å¹³å‡å¹€æ•¸: {sum(frame_counts)/len(frame_counts):.1f} å¹€")
                
                # é¡¯ç¤ºåˆ†å‰²çµ±è¨ˆ
                original_group_sizes = [len(group_dets) for group_dets in initial_groups.values()]
                if original_group_sizes:
                    large_groups = [size for size in original_group_sizes if size > max_frames]
                    if large_groups:
                        print(f"  - å¤§å‹çµ„åˆ¥åˆ†å‰²: {len(large_groups)} å€‹çµ„åˆ¥è¢«åˆ†å‰²")
                        print(f"  - åˆ†å‰²å‰æœ€å¤§çµ„åˆ¥: {max(original_group_sizes)} å¹€")
            
            return events
        except Exception as e:
            print(f"åˆ†çµ„åµæ¸¬çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []
    
    def _process_event_chunk(self, group_dets, event_dir, event_id, events):
        """è™•ç†ä¸€å€‹äº‹ä»¶å¡Šï¼Œå°‡å…¶ä¿å­˜ä¸¦æ·»åŠ åˆ°äº‹ä»¶åˆ—è¡¨"""
        frames = []
        for i, det in enumerate(group_dets):
            # ä¿å­˜è£åˆ‡åœ–ç‰‡
            crop_path = event_dir / f"crop_{i:03d}_{det['timestamp']:.1f}s.jpg"
            cv2.imwrite(str(crop_path), det['crop'])
            
            # åœ¨å®Œæ•´ç•«é¢ä¸Šç¹ªè£½æ¡†ç·š
            full_frame = det['full_frame'].copy()
            x1, y1, x2, y2 = [int(v) for v in det['bbox']]
            cv2.rectangle(full_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
            cv2.putText(full_frame, f"Conf: {det['confidence']:.2f}", 
                       (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # ä¿å­˜å¸¶æ¡†ç·šçš„å®Œæ•´ç•«é¢
            full_path = event_dir / f"full_{i:03d}_{det['timestamp']:.1f}s.jpg"
            cv2.imwrite(str(full_path), full_frame)
            
            frames.append({
                'crop_path': str(crop_path),
                'full_path': str(full_path),
                'image_path': str(crop_path),  # ä¿æŒç›¸å®¹æ€§
                'timestamp': det['timestamp'],
                'confidence': det['confidence'],
                'bbox': det['bbox'],
                'video_name': det.get('video_name', 'unknown'),
                'video_idx': det.get('video_idx', 0)
            })
        
        # ç²å–ä¸»è¦å½±ç‰‡ä¾†æº
        video_names = list(set(det.get('video_name', 'unknown') for det in group_dets))
        primary_video = video_names[0] if len(video_names) == 1 else 'multiple'
        
        event = {
            'id': event_id,
            'frames': frames,
            'start_time': float(group_dets[0]['timestamp']),
            'end_time': float(group_dets[-1]['timestamp']),
            'duration': float(group_dets[-1]['timestamp'] - group_dets[0]['timestamp']),
            'frame_count': len(group_dets),
            'avg_confidence': float(np.mean([d['confidence'] for d in group_dets])),
            'video_name': primary_video,
            'video_names': video_names,
            'label': None  # å¾…æ¨™è¨»
        }
        events.append(event)
    
    def _format_progress_text(self):
        """æ ¼å¼åŒ–é€²åº¦æ–‡å­—"""
        lines = [f"ğŸ“Š åˆ†æé€²åº¦ ({len(self.analysis_status)} å€‹å½±ç‰‡):"]
        lines.append("")
        
        for idx, status in self.analysis_status.items():
            name = status['name'][:30] + "..." if len(status['name']) > 30 else status['name']
            
            if status['status'] == 'ç­‰å¾…ä¸­':
                lines.append(f"â³ {name}: ç­‰å¾…ä¸­")
            elif status['status'] == 'è™•ç†ä¸­':
                progress = status.get('progress', 0)
                detections = status.get('detections', 0)
                lines.append(f"ğŸ”„ {name}: {progress}% ({detections} å€‹åµæ¸¬)")
            elif status['status'] == 'å®Œæˆ':
                detections = status.get('detections', 0)
                lines.append(f"âœ… {name}: å®Œæˆ ({detections} å€‹åµæ¸¬)")
            elif status['status'] == 'éŒ¯èª¤':
                error = status.get('error', 'æœªçŸ¥éŒ¯èª¤')
                lines.append(f"âŒ {name}: éŒ¯èª¤ - {error}")
        
        return "\n".join(lines)
    
    def _cleanup_old_sessions(self):
        """æ¸…ç†èˆŠçš„åˆ†ææœƒè©±ä»¥ç¯€çœç£ç¢Ÿç©ºé–“"""
        try:
            if not self.work_dir.exists():
                return
                
            import time
            current_time = time.time()
            
            for session_path in self.work_dir.iterdir():
                if session_path.is_dir():
                    if current_time - session_path.stat().st_mtime > 3600:  # 1å°æ™‚
                        import shutil
                        shutil.rmtree(session_path, ignore_errors=True)
                        print(f"æ¸…ç†èˆŠæœƒè©±: {session_path.name}")
        except Exception as e:
            print(f"æ¸…ç†èˆŠæœƒè©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _optimize_memory_usage(self):
        """å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"""
        if not MEMORY_MONITORING_AVAILABLE:
            return 0
            
        try:
            # å¼·åˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            process = psutil.Process(os.getpid())
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            
            if memory_usage > 8000:  # å¦‚æœè¶…é8GB
                print(f"âš ï¸  è¨˜æ†¶é«”ä½¿ç”¨é‡è¼ƒé«˜: {memory_usage:.1f} MB")
                gc.collect()
                
            return memory_usage
        except Exception as e:
            print(f"è¨˜æ†¶é«”ç›£æ§éŒ¯èª¤: {e}")
            return 0