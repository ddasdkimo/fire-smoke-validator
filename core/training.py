#!/usr/bin/env python3
"""
è¨“ç·´æ¨¡çµ„
è² è²¬æ¨¡å‹è¨“ç·´åŠŸèƒ½
"""

import os
import zipfile
from pathlib import Path
import json
import tempfile
import shutil
from datetime import datetime

try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False


class ModelTrainer:
    """æ¨¡å‹è¨“ç·´å™¨"""
    
    def __init__(self):
        self.training_dir = Path("training_workspace")
        self.training_dir.mkdir(exist_ok=True)
        
        # æ”¯æ´çš„æ¨¡å‹é¡å‹
        self.supported_models = {
            "yolov8n.pt": "YOLOv8 Nano - è¼•é‡ç´šï¼Œé€Ÿåº¦å¿«",
            "yolov8s.pt": "YOLOv8 Small - å¹³è¡¡æ€§èƒ½èˆ‡é€Ÿåº¦", 
            "yolov8m.pt": "YOLOv8 Medium - è¼ƒé«˜ç²¾åº¦",
            "yolov8l.pt": "YOLOv8 Large - é«˜ç²¾åº¦",
            "yolov8x.pt": "YOLOv8 Extra Large - æœ€é«˜ç²¾åº¦"
        }
        
        # è¨“ç·´ç‹€æ…‹
        self.is_training = False
        self.training_progress = ""
        self.training_results = None
    
    def upload_and_extract_dataset(self, zip_file):
        """ä¸Šå‚³ä¸¦è§£å£“æ¨™è¨»è³‡æ–™é›†"""
        try:
            if not zip_file:
                return "è«‹é¸æ“‡æ¨™è¨»è³‡æ–™é›†ZIPæª”æ¡ˆ"
            
            # å»ºç«‹æ–°çš„è³‡æ–™é›†ç›®éŒ„
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            dataset_dir = self.training_dir / f"dataset_{timestamp}"
            dataset_dir.mkdir(exist_ok=True)
            
            # è§£å£“æª”æ¡ˆ
            with zipfile.ZipFile(zip_file.name, 'r') as zip_ref:
                zip_ref.extractall(dataset_dir)
            
            # é©—è­‰è³‡æ–™é›†çµæ§‹
            validation_result = self._validate_dataset_structure(dataset_dir)
            if not validation_result["valid"]:
                shutil.rmtree(dataset_dir)
                return f"âŒ è³‡æ–™é›†æ ¼å¼éŒ¯èª¤: {validation_result['error']}"
            
            # è½‰æ›ç‚ºYOLOæ ¼å¼
            yolo_dataset_dir = self._convert_to_yolo_format(dataset_dir, validation_result["stats"])
            
            return f"""âœ… è³‡æ–™é›†ä¸Šå‚³æˆåŠŸï¼
            
ğŸ“Š è³‡æ–™é›†çµ±è¨ˆ:
- çœŸå¯¦ç«ç…™äº‹ä»¶: {validation_result['stats']['true_positive']} å€‹
- èª¤åˆ¤äº‹ä»¶: {validation_result['stats']['false_positive']} å€‹  
- ç¸½å½±åƒæ•¸: {validation_result['stats']['total_images']} å¼µ

ğŸ“ è³‡æ–™é›†è·¯å¾‘: {yolo_dataset_dir}
            """
            
        except Exception as e:
            return f"âŒ ä¸Šå‚³å¤±æ•—: {str(e)}"
    
    def _validate_dataset_structure(self, dataset_dir):
        """é©—è­‰è³‡æ–™é›†çµæ§‹"""
        try:
            true_positive_dir = dataset_dir / "true_positive"
            false_positive_dir = dataset_dir / "false_positive"
            
            if not true_positive_dir.exists() or not false_positive_dir.exists():
                return {"valid": False, "error": "ç¼ºå°‘ true_positive æˆ– false_positive è³‡æ–™å¤¾"}
            
            # çµ±è¨ˆäº‹ä»¶å’Œå½±åƒæ•¸é‡
            true_events = list(true_positive_dir.iterdir()) if true_positive_dir.exists() else []
            false_events = list(false_positive_dir.iterdir()) if false_positive_dir.exists() else []
            
            total_images = 0
            for event_dir in true_events + false_events:
                if event_dir.is_dir():
                    images = list(event_dir.glob("*.jpg"))
                    total_images += len(images)
            
            stats = {
                "true_positive": len(true_events),
                "false_positive": len(false_events),
                "total_images": total_images
            }
            
            if total_images == 0:
                return {"valid": False, "error": "æœªæ‰¾åˆ°ä»»ä½•å½±åƒæª”æ¡ˆ"}
            
            return {"valid": True, "stats": stats}
            
        except Exception as e:
            return {"valid": False, "error": str(e)}
    
    def _convert_to_yolo_format(self, dataset_dir, stats):
        """è½‰æ›ç‚ºYOLOè¨“ç·´æ ¼å¼"""
        # é€™è£¡å»ºç«‹åŸºæœ¬çš„YOLOè³‡æ–™é›†çµæ§‹
        # å¯¦éš›å¯¦ä½œæ™‚æœƒæ ¹æ“šå…·é«”éœ€æ±‚èª¿æ•´
        yolo_dir = dataset_dir.parent / f"yolo_{dataset_dir.name}"
        yolo_dir.mkdir(exist_ok=True)
        
        # å»ºç«‹åŸºæœ¬ç›®éŒ„çµæ§‹
        (yolo_dir / "images" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_dir / "images" / "val").mkdir(parents=True, exist_ok=True)
        (yolo_dir / "labels" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_dir / "labels" / "val").mkdir(parents=True, exist_ok=True)
        
        # å»ºç«‹dataset.yamlé…ç½®æª”
        dataset_config = {
            "train": str(yolo_dir / "images" / "train"),
            "val": str(yolo_dir / "images" / "val"),
            "nc": 2,  # é¡åˆ¥æ•¸é‡: ç«ç…™, ç„¡ç«ç…™
            "names": ["fire_smoke", "no_fire_smoke"]
        }
        
        with open(yolo_dir / "dataset.yaml", "w", encoding="utf-8") as f:
            if YAML_AVAILABLE:
                yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)
            else:
                # å¦‚æœæ²’æœ‰ yamlï¼Œæ‰‹å‹•å¯«å…¥é…ç½®
                f.write(f"train: {dataset_config['train']}\n")
                f.write(f"val: {dataset_config['val']}\n")
                f.write(f"nc: {dataset_config['nc']}\n")
                f.write(f"names: {dataset_config['names']}\n")
        
        return yolo_dir
    
    def get_available_models(self):
        """å–å¾—å¯ç”¨çš„é è¨“ç·´æ¨¡å‹åˆ—è¡¨"""
        return list(self.supported_models.keys())
    
    def get_model_info(self, model_name):
        """å–å¾—æ¨¡å‹è³‡è¨Š"""
        return self.supported_models.get(model_name, "æœªçŸ¥æ¨¡å‹")
    
    def start_training(self, dataset_path, model_name, epochs, batch_size, image_size):
        """é–‹å§‹è¨“ç·´æ¨¡å‹"""
        try:
            if not ULTRALYTICS_AVAILABLE:
                return "âŒ æœªå®‰è£ ultralytics å¥—ä»¶ï¼Œç„¡æ³•é€²è¡Œè¨“ç·´"
            
            if self.is_training:
                return "âš ï¸ å·²æœ‰è¨“ç·´æ­£åœ¨é€²è¡Œä¸­"
            
            # é©—è­‰åƒæ•¸
            if not Path(dataset_path).exists():
                return "âŒ è³‡æ–™é›†è·¯å¾‘ä¸å­˜åœ¨"
            
            # è¨­å®šè¨“ç·´åƒæ•¸
            self.is_training = True
            self.training_progress = "ğŸš€ æº–å‚™é–‹å§‹è¨“ç·´..."
            
            # å¯¦éš›è¨“ç·´é‚è¼¯æœƒåœ¨é€™è£¡å¯¦ä½œ
            # é€™è£¡å…ˆå»ºç«‹æ¡†æ¶
            
            return f"""âœ… è¨“ç·´ä»»å‹™å·²å•Ÿå‹•ï¼
            
ğŸ¯ è¨“ç·´è¨­å®š:
- è³‡æ–™é›†: {dataset_path}
- åŸºç¤æ¨¡å‹: {model_name}
- è¨“ç·´è¼ªæ•¸: {epochs}
- æ‰¹æ¬¡å¤§å°: {batch_size}
- å½±åƒå°ºå¯¸: {image_size}

ğŸ“Š è«‹é—œæ³¨ä¸‹æ–¹é€²åº¦é¡¯ç¤º...
            """
            
        except Exception as e:
            self.is_training = False
            return f"âŒ è¨“ç·´å•Ÿå‹•å¤±æ•—: {str(e)}"
    
    def get_training_progress(self):
        """å–å¾—è¨“ç·´é€²åº¦"""
        if not self.is_training:
            return "ç­‰å¾…é–‹å§‹è¨“ç·´..."
        return self.training_progress
    
    def stop_training(self):
        """åœæ­¢è¨“ç·´"""
        if self.is_training:
            self.is_training = False
            self.training_progress = "â¹ï¸ è¨“ç·´å·²åœæ­¢"
            return "âœ… è¨“ç·´å·²åœæ­¢"
        return "âš ï¸ æ²’æœ‰æ­£åœ¨é€²è¡Œçš„è¨“ç·´"
    
    def list_trained_models(self):
        """åˆ—å‡ºå·²è¨“ç·´çš„æ¨¡å‹"""
        runs_dir = Path("runs/detect")
        if not runs_dir.exists():
            return []
        
        models = []
        for run_dir in runs_dir.iterdir():
            if run_dir.is_dir():
                weights_dir = run_dir / "weights"
                if weights_dir.exists():
                    best_pt = weights_dir / "best.pt"
                    if best_pt.exists():
                        models.append({
                            "name": run_dir.name,
                            "path": str(best_pt),
                            "created": best_pt.stat().st_mtime
                        })
        
        # æŒ‰å»ºç«‹æ™‚é–“æ’åº
        models.sort(key=lambda x: x["created"], reverse=True)
        return models